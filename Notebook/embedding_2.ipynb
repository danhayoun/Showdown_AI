{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire actuel : /Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/My_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipynbname\n",
    "\n",
    "chemin_notebook = ipynbname.path()\n",
    "dossier_notebook = os.path.dirname(chemin_notebook)\n",
    "os.chdir(dossier_notebook)\n",
    "os.chdir('..')\n",
    "print(\"Répertoire actuel :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.embedding import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va modifier l'embedding des types. On va réaliser un autoencodeur pour représenter la répart des types des pokes dans un espace 3 (et non 18). On garde un ordre dans ces représentations, car savoir quel type correspond à quel poké est important. Aussi on peut rajouter le nb_fainted, mais un vecteur 12 dim avec les positions des pokémons fainted, ça peut aider je pense à éviter les fausses actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=12, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=12, out_features=4, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=12, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=12, out_features=18, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instancier l'encodeur du type \n",
    "from Utils.autoencodeur.type.type_autoencodeur import TypeAutoencoder\n",
    "\n",
    "encodeur_type = TypeAutoencoder(encoded_size=4)\n",
    "\n",
    "# Charger les poids sauvegardés\n",
    "encodeur_type.load_state_dict(torch.load(\"Utils/autoencodeur/type/type_autoencoder.pth\", map_location='mps'))\n",
    "encodeur_type.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodeur créé. Maintenant on remplace les types par les vecteurs encodés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## DEFINIR L'EMBEDDING ##################\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Space, Box\n",
    "from poke_env.player import Gen8EnvSinglePlayer\n",
    "from poke_env.data import GenData\n",
    "import numpy as np\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "import torch\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "# Initialiser GenData pour la génération souhaitée (par exemple, génération 8)\n",
    "gen_data = GenData.from_gen(8)\n",
    "\n",
    "# Accéder au tableau des types\n",
    "type_chart = gen_data.type_chart\n",
    "\n",
    "\n",
    "class embedding_Player(Gen8EnvSinglePlayer):\n",
    "    def __init__(self,model_path=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if model_path is not None :\n",
    "            self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "            print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "\n",
    "        self.action_space = Discrete(9)  # ✅ attribut classique\n",
    "    \n",
    "    #Toujours mêmes valeurs de reward\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        pokemon_types_compressed = []\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "        pokemon_types = torch.tensor(obtain_pokemon_types(battle)).view(12, 18)  # 6 pokés par team = 12 vecteurs\n",
    "        with torch.no_grad():\n",
    "            for i in range(12) :\n",
    "                vec = pokemon_types[i].unsqueeze(0)\n",
    "                encoded = encodeur_type.encoder(vec.float()) \n",
    "                pokemon_types_compressed.append(encoded.squeeze(0))\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        compressed_flat = torch.cat(pokemon_types_compressed).numpy()\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                compressed_flat,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = (\n",
    "            [-1] * 4 +          # real power\n",
    "            [0] * 24 +         # my team types\n",
    "            [0] * 24           # opponent team types\n",
    "        )\n",
    "        high = (\n",
    "            [3] * 4 +           # real power\n",
    "            [1] * 24 +         # my team types\n",
    "            [1] * 24           # opponent team types\n",
    "        )\n",
    "\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def action_to_move(self, action: int, battle: AbstractBattle):\n",
    "        order = super().action_to_move(action, battle)\n",
    "        order.dynamax = False  # 🔥 désactive Dynamax pour toutes les actions\n",
    "        return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DEFINIR MODELE ##################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Réseau perceptron à une couche cachée, sortie linéaire, f activation = Relu,\n",
    "class DQNModel(nn.Module):\n",
    "    def __init__(self, input_dim, n_actions):\n",
    "        super(DQNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv12= nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.out = nn.Linear(32, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        real_power = x[:4]\n",
    "        types = x[4:] \n",
    "        real_power_padded = F.pad(real_power, (0, 14))  # [18]\n",
    "        real_power_padded = real_power_padded.unsqueeze(0)  # [1, 18] \n",
    "        sequence = torch.cat([real_power_padded, types], dim=0)\n",
    "        sequence = sequence.T.unsqueeze(0)     \n",
    "        types = types.view(12, 18) \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRAINING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opponent = NoDynamaxRandomPlayer(battle_format=\"gen8randombattle\")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# instanciation du player\n",
    "train_env_raw = embedding_Player(\n",
    "    battle_format=\"gen8randombattle\",\n",
    "    opponent=RandomPlayer(battle_format=\"gen8randombattle\"),\n",
    "    start_challenging=True\n",
    ")\n",
    "\n",
    "# wrap dans DummyVecEnv (SB3 attend un vecteur d’envs, même pour un seul)\n",
    "train_env = DummyVecEnv([lambda: train_env_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = train_env\n",
    "\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=2.5e-4,\n",
    "    buffer_size=10000,\n",
    "    learning_starts=1000,\n",
    "    batch_size=32,\n",
    "    gamma=0.5,\n",
    "    train_freq=1,\n",
    "    target_update_interval=1,\n",
    "    exploration_fraction=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    policy_kwargs=dict(activation_fn=nn.ReLU, net_arch=[128, 64])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = 50000\n",
    "#callback = CustomTQDMCallback(total_timesteps = steps, check_freq=1000, verbose=1)\n",
    "#model.learn(\n",
    "#    total_timesteps=steps,\n",
    "#    callback=callback\n",
    "#)\n",
    "#model.save(\"Players/embedding_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "class EmbeddingTestPlayer(Gen8EnvSinglePlayer):\n",
    "\n",
    "    def __init__(self, model_path=\"Players/embedding_2\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "        print(\"Répertoire actuel :\", os.getcwd())\n",
    "\n",
    "        #Toujours mêmes valeurs de reward\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        pokemon_types_compressed = []\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "        pokemon_types = torch.tensor(obtain_pokemon_types(battle)).view(12, 18)  # 6 pokés par team = 12 vecteurs\n",
    "        with torch.no_grad():\n",
    "            for i in range(12) :\n",
    "                vec = pokemon_types[i].unsqueeze(0)\n",
    "                encoded = encodeur_type.encoder(vec.float()) \n",
    "                pokemon_types_compressed.append(encoded.squeeze(0))\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        compressed_flat = torch.cat(pokemon_types_compressed).numpy()\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                compressed_flat,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = (\n",
    "            [-1] * 4 +          # real power\n",
    "            [0] * 24 +         # my team types\n",
    "            [0] * 24           # opponent team types\n",
    "        )\n",
    "        high = (\n",
    "            [3] * 4 +           # real power\n",
    "            [1] * 24 +         # my team types\n",
    "            [1] * 24           # opponent team types\n",
    "        )\n",
    "\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def action_to_move(self, action, battle):\n",
    "        moves = battle.available_moves\n",
    "        switches = battle.available_switches\n",
    "        total_actions = len(moves) + len(switches)\n",
    "\n",
    "        #print(f\"🔢 DQN → action={action} | #moves={len(moves)} | #switches={len(switches)} | total={total_actions}\")\n",
    "\n",
    "        if 0 <= action < len(moves):\n",
    "            return self.create_order(moves[action])\n",
    "        elif len(moves) <= action < total_actions:\n",
    "            return self.create_order(switches[action - len(moves)])\n",
    "        else:\n",
    "            #print(\"❌ Action hors bornes ! Fallback sur move aléatoire\")\n",
    "            return self.choose_random_move(battle)\n",
    "        \n",
    "    def predict(self, obs):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        q_values = self.model.q_net(obs_tensor)\n",
    "        print(f\"📊 Q-values : {q_values.detach().numpy().flatten()}\")\n",
    "        action = int(torch.argmax(q_values).item())\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire actuel : /Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/My_project\n",
      "📥 Modèle chargé depuis Players/embedding_2\n",
      "Répertoire actuel : /Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/My_project\n"
     ]
    }
   ],
   "source": [
    "print(\"Répertoire actuel :\", os.getcwd())\n",
    "opponent = NoDynamaxRandomPlayer(battle_format=\"gen8randombattle\")\n",
    "eval_env = EmbeddingTestPlayer(\n",
    "    battle_format=\"gen8randombattle\", opponent=opponent, start_challenging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e333e398f1c544f2b8c579864106a4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 0 victoires sur 1 matchs\n",
      "🎯 Reward moyen : -37.72\n"
     ]
    }
   ],
   "source": [
    "n_eval_episodes = 1\n",
    "rewards = []\n",
    "wins = 0\n",
    "\n",
    "obs, _ = eval_env.reset()\n",
    "for _ in tqdm(range(n_eval_episodes)):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        total_reward += reward\n",
    "        if done and reward > 0:\n",
    "            wins += 1\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    obs, _ = eval_env.reset()\n",
    "\n",
    "print(f\"✅ {wins} victoires sur {n_eval_episodes} matchs\")\n",
    "print(f\"🎯 Reward moyen : {sum(rewards) / len(rewards):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialTrainPlayer(RandomPlayer):\n",
    "\n",
    "    def __init__(self, model_path=\"Players/embedding_2\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "\n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        pokemon_types_compressed = []\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "        pokemon_types = torch.tensor(obtain_pokemon_types(battle)).view(12, 18)  # 6 pokés par team = 12 vecteurs\n",
    "        with torch.no_grad():\n",
    "            for i in range(12) :\n",
    "                vec = pokemon_types[i].unsqueeze(0)\n",
    "                encoded = encodeur_type.encoder(vec.float()) \n",
    "                pokemon_types_compressed.append(encoded.squeeze(0))\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        compressed_flat = torch.cat(pokemon_types_compressed).numpy()\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                compressed_flat,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "    \n",
    "    #action_to_move suppr\n",
    "        \n",
    "    def predict(self, obs):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        q_values = self.model.q_net(obs_tensor)\n",
    "        print(f\"📊 Q-values : {q_values.detach().numpy().flatten()}\")\n",
    "        action = int(torch.argmax(q_values).item())\n",
    "        return action\n",
    "    \n",
    "    def choose_move(self, battle):\n",
    "        obs = self.embed_battle(battle)\n",
    "        device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(obs_tensor)\n",
    "            action = int(torch.argmax(q_values).item())\n",
    "\n",
    "        moves = battle.available_moves\n",
    "        switches = battle.available_switches\n",
    "        total_actions = len(moves) + len(switches)\n",
    "\n",
    "        if 0 <= action < len(moves):\n",
    "            return self.create_order(moves[action])\n",
    "        elif len(moves) <= action < total_actions:\n",
    "            return self.create_order(switches[action - len(moves)])\n",
    "        else:\n",
    "            return self.choose_random_move(battle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle chargé depuis Players/embedding_2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_env_raw = embedding_Player(\n",
    "    battle_format=\"gen8randombattle\",\n",
    "    opponent=AdversarialTrainPlayer(battle_format=\"gen8randombattle\"),\n",
    "    start_challenging=True\n",
    ")\n",
    "train_env = DummyVecEnv([lambda: train_env_raw])\n",
    "\n",
    "#adv_learn_model = DQN.load(\"Players/embedding_2\", env=train_env, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Puis on continue l'entraînement\n",
    "#adv_learn_model.learn(total_timesteps=10000)\n",
    "\n",
    "#adv_learn_model.save(\"Players/embedding_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle chargé depuis Players/embedding_2\n",
      "📥 Modèle chargé depuis Players/embedding_3\n",
      "Répertoire actuel : /Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/My_project\n"
     ]
    }
   ],
   "source": [
    "opponent = AdversarialTrainPlayer(battle_format=\"gen8randombattle\")\n",
    "\n",
    "eval_env = EmbeddingTestPlayer(\n",
    "    battle_format=\"gen8randombattle\", opponent=opponent, start_challenging=True, model_path=\"Players/embedding_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1954cddd0ae4811bce6743fc17483e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 0 victoires sur 1 matchs\n",
      "🎯 Reward moyen : -34.83\n"
     ]
    }
   ],
   "source": [
    "n_eval_episodes = 1\n",
    "rewards = []\n",
    "wins = 0\n",
    "\n",
    "obs, _ = eval_env.reset()\n",
    "for _ in tqdm(range(n_eval_episodes)):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        total_reward += reward\n",
    "        if done and reward > 0:\n",
    "            wins += 1\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    obs, _ = eval_env.reset()\n",
    "\n",
    "print(f\"✅ {wins} victoires sur {n_eval_episodes} matchs\")\n",
    "print(f\"🎯 Reward moyen : {sum(rewards) / len(rewards):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais l'affronter moi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DQ_simple import DQ_simple \n",
    "class DQ_simpleemb3(DQ_simple) :\n",
    "    def __init__(self, model_path = \"Players/embedding_3\", battle_format=\"gen8randombattle\"):\n",
    "        super().__init__(battle_format=battle_format)\n",
    "        \n",
    "        self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(\"📥 Modèle DQN chargé :\", self.model)\n",
    "    \n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "            moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        #Pokemon types  \n",
    "        pokemon_types_compressed = []\n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "        pokemon_types = torch.tensor(obtain_pokemon_types(battle)).view(12, 18)  # 6 pokés par team = 12 vecteurs\n",
    "        with torch.no_grad():\n",
    "            for i in range(12) :\n",
    "                vec = pokemon_types[i].unsqueeze(0)\n",
    "                encoded = encodeur_type.encoder(vec.float()) \n",
    "                pokemon_types_compressed.append(encoded.squeeze(0))\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        compressed_flat = torch.cat(pokemon_types_compressed).numpy()\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                compressed_flat,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def choose_move(self, battle):\n",
    "        print(\"👉 choose_move appelée !\")\n",
    "        # 🔍 Debug : Voir les moves disponibles\n",
    "        print(f\"🔍 Moves disponibles : {[move.id for move in battle.available_moves]}\")\n",
    "\n",
    "        # Obtenir l'observation de l'état du combat\n",
    "        obs = self.embed_battle(battle)\n",
    "        print(\"📊 Observation de l'état :\", obs)\n",
    "\n",
    "        # Transformer en format PyTorch\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        print(\"📊 Tensor pour le modèle :\", obs_tensor)\n",
    "\n",
    "        # Prédire l'action avec le modèle DQN\n",
    "        action = int(self.model.predict(obs_tensor, deterministic=True)[0])\n",
    "        \n",
    "        print(\"🎯 Action choisie par DQN :\", action)\n",
    "        moves = battle.available_moves\n",
    "        switches = battle.available_switches\n",
    "        total_actions = len(moves) + len(switches)\n",
    "        self.create_order.dynamax = False\n",
    "\n",
    "        if 0 <= action < len(moves):\n",
    "            return self.create_order(moves[action])\n",
    "        elif len(moves) <= action < total_actions:\n",
    "            return self.create_order(switches[action - len(moves)])\n",
    "        else:\n",
    "            print(\"XXXX   : Random Moove \")\n",
    "            return self.choose_random_move(battle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle DQN chargé : <stable_baselines3.dqn.dqn.DQN object at 0x15ed63310>\n",
      "📥 Modèle DQN chargé : <stable_baselines3.dqn.dqn.DQN object at 0x15ed6d9d0>\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          1.5         0.45        0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.0553175   1.4143128  -0.56194496  0.49795628 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.6891162   1.1604713\n",
      " -0.8384739   0.86872107 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  1.5000,  0.4500,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.0553,  1.4143, -0.5619,  0.4980,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.6891,  1.1605, -0.8385,  0.8687,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/sk18hvh55gqbml8209nmkrlc0000gq/T/ipykernel_31401/204959055.py:62: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  action = int(self.model.predict(obs_tensor, deterministic=True)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          0.375       0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.0553175   1.4143128  -0.56194496  0.49795628 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3750,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.0553,  1.4143, -0.5619,  0.4980,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 5\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['closecombat', 'outrage', 'dragondance', 'headsmash']\n",
      "📊 Observation de l'état : [ 2.4         1.2         0.          0.75       -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.0553175   1.4143128  -0.56194496  0.49795628 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 2.4000,  1.2000,  0.0000,  0.7500, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.0553,  1.4143, -0.5619,  0.4980,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 0\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : []\n",
      "📊 Observation de l'état : [-1.         -1.         -1.         -1.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          0.375       0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3750,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 5\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['closecombat', 'bravebird', 'stoneedge', 'swordsdance']\n",
      "📊 Observation de l'état : [ 2.4         0.6         0.5         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.9057633   0.99372894\n",
      " -1.1991675   0.9391059  -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 2.4000,  0.6000,  0.5000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.9058,  0.9937, -1.1992,  0.9391, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 0\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : []\n",
      "📊 Observation de l'état : [-1.         -1.         -1.         -1.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          0.375       0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3750,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 5\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['trick', 'knockoff', 'zenheadbutt', 'closecombat']\n",
      "📊 Observation de l'état : [ 0.          0.65        0.8         2.4        -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.1690445   1.6854677  -0.6401736   0.5895755\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.6500,  0.8000,  2.4000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1690,  1.6855, -0.6402,  0.5896, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['closecombat']\n",
      "📊 Observation de l'état : [ 0.6        -1.         -1.         -1.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.6000, -1.0000, -1.0000, -1.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 01:42:50,919 - DQ_simpleemb3 3 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Gyarados', 'Bounce', 'p1a: Wishiwashi', '[from] lockedmove'] in battle battle-gen8randombattle-6500 turn 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.9         0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -2.129465    0.48220807 -1.1449594   0.99173605 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.9000,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -2.1295,  0.4822, -1.1450,  0.9917,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 01:42:55,409 - DQ_simpleemb3 3 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Gyarados', 'Bounce', 'p1a: Wishiwashi', '[from] lockedmove'] in battle battle-gen8randombattle-6500 turn 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.45        1.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.4500,  1.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 5\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          1.5         0.45        0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  1.5000,  0.4500,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['sleeppowder', 'airslash', 'bugbuzz', 'quiverdance']\n",
      "📊 Observation de l'état : [ 0.          1.5         0.45        0.         -1.7605909   0.6749176\n",
      " -0.845018    0.83518666 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  1.5000,  0.4500,  0.0000, -1.7606,  0.6749, -0.8450,  0.8352,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : []\n",
      "📊 Observation de l'état : [-1.         -1.         -1.         -1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.45        1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.4500,  1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.45        1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.4500,  1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['uturn', 'scald', 'icebeam', 'earthquake']\n",
      "📊 Observation de l'état : [ 0.35        0.4         0.45        1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.5516384   0.791832   -0.8793163   0.74129087 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3500,  0.4000,  0.4500,  1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.5516,  0.7918, -0.8793,  0.7413, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : []\n",
      "📊 Observation de l'état : [-1.         -1.         -1.         -1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['trick', 'knockoff', 'zenheadbutt', 'closecombat']\n",
      "📊 Observation de l'état : [ 0.          0.325       1.6         1.2        -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3250,  1.6000,  1.2000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 7\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['trick', 'knockoff', 'zenheadbutt', 'closecombat']\n",
      "📊 Observation de l'état : [ 0.          0.325       1.6         1.2        -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3250,  1.6000,  1.2000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 7\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['knockoff', 'bodyslam', 'swordsdance', 'explosion']\n",
      "📊 Observation de l'état : [ 0.325       0.85        0.          2.5        -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.544438    1.5230358  -1.0729465   0.8510073\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.3250,  0.8500,  0.0000,  2.5000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.5444,  1.5230, -1.0729,  0.8510, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 3\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : []\n",
      "📊 Observation de l'état : [-1.         -1.         -1.         -1.         -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 1\n",
      "👉 choose_move appelée !\n",
      "🔍 Moves disponibles : ['trick', 'knockoff', 'zenheadbutt', 'closecombat']\n",
      "📊 Observation de l'état : [ 0.          0.325       1.6         1.2        -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.8650103   1.3752306  -1.1475861   0.9287637\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.152232    1.0118549\n",
      " -0.49244103  0.46972787 -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787 -1.7280061   1.0265892\n",
      " -1.2733984   0.9492904  -1.152232    1.0118549  -0.49244103  0.46972787\n",
      " -1.152232    1.0118549  -0.49244103  0.46972787]\n",
      "📊 Tensor pour le modèle : tensor([[ 0.0000,  0.3250,  1.6000,  1.2000, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.8650,  1.3752, -1.1476,  0.9288,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.7280,  1.0266, -1.2734,  0.9493, -1.1522,  1.0119, -0.4924,  0.4697,\n",
      "         -1.1522,  1.0119, -0.4924,  0.4697]])\n",
      "🎯 Action choisie par DQN : 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bott_player = DQ_simpleemb3()\n",
    "\n",
    "await bott_player.send_challenges(\"[NAME]\", n_challenges=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "showdown_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "455d2c1a4ef8d735c62ff6b7867677aa8f5a8db787748daaa4d34b19b9911963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
