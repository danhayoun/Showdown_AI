{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import poke_env\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ne sais pas vraiment sur quels types d'encodages partir donc on va en essayer plusieurs.\n",
    "Ce qui est sûr c'est que je veux prendre en compte les pokémons en questions joués, leurs mooves, leur speed, leurs stats, plus tard leurs objets.\n",
    "\n",
    "La question c'est comment on représente toutes ces valeurs qui ne sont pas continues ? (id pokémon/type, moovepool)\n",
    "\n",
    "On va essayer différentes méthodes : \n",
    "\n",
    "1) on ne prend pas en compte les ids des pokés, juste leurs types. Pour les mooves, on prend en compte le type et la puissance. Pour représenter le type : one-hot encoding. donc on aura 1 one-hot encoding pour le type du poké, puis 1 pour chacun de ses mooves. Comment relier ça à la table des types ? On va la recréer sous forme de matrice. Emplacement de chaque type (normal = ligne/colonne 1, fire = ligne/colonne 2 etc ..) =\n",
    "\n",
    "{normal, fire, water, electric, grass, ice, fighting, poison, ground, flying, psychic, bug, rock, ghost, dragon, dark, steel, fairy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 0.  1.  1.  0.5 1. ]\n",
      " [1.  0.5 0.5 1.  2.  2.  1.  1.  1.  1.  1.  2.  0.5 1.  0.5 1.  2.  1. ]\n",
      " [1.  2.  0.5 1.  0.5 1.  1.  1.  2.  1.  1.  1.  2.  1.  0.5 1.  1.  1. ]\n",
      " [1.  1.  2.  0.5 0.5 1.  1.  1.  0.  2.  1.  1.  1.  1.  0.5 1.  1.  1. ]\n",
      " [1.  0.5 2.  1.  0.5 1.  1.  0.5 2.  0.5 1.  0.5 2.  1.  0.5 1.  0.5 1. ]\n",
      " [1.  0.5 0.5 1.  2.  0.5 1.  1.  2.  2.  1.  1.  1.  1.  2.  1.  0.5 1. ]\n",
      " [2.  1.  1.  1.  1.  2.  1.  0.5 1.  0.5 0.5 0.5 2.  0.  1.  2.  2.  0.5]\n",
      " [1.  1.  1.  1.  2.  1.  1.  0.5 0.5 1.  1.  1.  0.5 0.5 1.  1.  0.  2. ]\n",
      " [1.  2.  1.  2.  0.5 1.  1.  2.  1.  0.  1.  0.5 2.  1.  1.  1.  2.  1. ]\n",
      " [1.  1.  1.  0.5 2.  1.  2.  1.  1.  1.  1.  2.  0.5 1.  1.  1.  0.5 1. ]\n",
      " [1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  0.5 1.  1.  1.  1.  0.  0.5 1. ]\n",
      " [1.  0.5 1.  1.  2.  1.  0.5 0.5 1.  0.5 2.  1.  1.  0.5 1.  2.  0.5 0.5]\n",
      " [1.  2.  1.  1.  1.  2.  0.5 1.  0.5 2.  1.  2.  1.  1.  1.  1.  0.5 1. ]\n",
      " [0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  2.  1.  0.5 1.  1. ]\n",
      " [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  0.5 0. ]\n",
      " [1.  1.  1.  1.  1.  1.  0.5 1.  1.  1.  2.  1.  1.  2.  1.  0.5 1.  0.5]\n",
      " [1.  0.5 0.5 0.5 1.  2.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  0.5 2. ]\n",
      " [1.  0.5 1.  1.  1.  1.  2.  0.5 1.  1.  1.  1.  1.  1.  2.  2.  0.5 1. ]]\n"
     ]
    }
   ],
   "source": [
    "#Table des types, forme matricielle\n",
    "type_list = [\n",
    "    \"normal\", \"fire\", \"water\", \"electric\", \"grass\", \"ice\", \"fighting\",\n",
    "    \"poison\", \"ground\", \"flying\", \"psychic\", \"bug\", \"rock\", \"ghost\",\n",
    "    \"dragon\", \"dark\", \"steel\", \"fairy\"\n",
    "]\n",
    "\n",
    "# Matrice des multiplicateurs d'après le tableau officiel des types Pokémon\n",
    "type_chart = {\n",
    "    \"normal\":   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0, 1, 1, 0.5, 1],\n",
    "    \"fire\":     [1, 0.5, 0.5, 1, 2, 2, 1, 1, 1, 1, 1, 2, 0.5, 1, 0.5, 1, 2, 1],\n",
    "    \"water\":    [1, 2, 0.5, 1, 0.5, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0.5, 1, 1, 1],\n",
    "    \"electric\": [1, 1, 2, 0.5, 0.5, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0.5, 1, 1, 1],\n",
    "    \"grass\":    [1, 0.5, 2, 1, 0.5, 1, 1, 0.5, 2, 0.5, 1, 0.5, 2, 1, 0.5, 1, 0.5, 1],\n",
    "    \"ice\":      [1, 0.5, 0.5, 1, 2, 0.5, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 0.5, 1],\n",
    "    \"fighting\": [2, 1, 1, 1, 1, 2, 1, 0.5, 1, 0.5, 0.5, 0.5, 2, 0, 1, 2, 2, 0.5],\n",
    "    \"poison\":   [1, 1, 1, 1, 2, 1, 1, 0.5, 0.5, 1, 1, 1, 0.5, 0.5, 1, 1, 0, 2],\n",
    "    \"ground\":   [1, 2, 1, 2, 0.5, 1, 1, 2, 1, 0, 1, 0.5, 2, 1, 1, 1, 2, 1],\n",
    "    \"flying\":   [1, 1, 1, 0.5, 2, 1, 2, 1, 1, 1, 1, 2, 0.5, 1, 1, 1, 0.5, 1],\n",
    "    \"psychic\":  [1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0.5, 1, 1, 1, 1, 0, 0.5, 1],\n",
    "    \"bug\":      [1, 0.5, 1, 1, 2, 1, 0.5, 0.5, 1, 0.5, 2, 1, 1, 0.5, 1, 2, 0.5, 0.5],\n",
    "    \"rock\":     [1, 2, 1, 1, 1, 2, 0.5, 1, 0.5, 2, 1, 2, 1, 1, 1, 1, 0.5, 1],\n",
    "    \"ghost\":    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0.5, 1, 1],\n",
    "    \"dragon\":   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0.5, 0],\n",
    "    \"dark\":     [1, 1, 1, 1, 1, 1, 0.5, 1, 1, 1, 2, 1, 1, 2, 1, 0.5, 1, 0.5],\n",
    "    \"steel\":    [1, 0.5, 0.5, 0.5, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0.5, 2],\n",
    "    \"fairy\":    [1, 0.5, 1, 1, 1, 1, 2, 0.5, 1, 1, 1, 1, 1, 1, 2, 2, 0.5, 1],\n",
    "}\n",
    "\n",
    "df_type_chart = pd.DataFrame(type_chart, index=type_list).T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "type_list = [\n",
    "    \"normal\", \"fire\", \"water\", \"electric\", \"grass\", \"ice\", \"fighting\",\n",
    "    \"poison\", \"ground\", \"flying\", \"psychic\", \"bug\", \"rock\", \"ghost\",\n",
    "    \"dragon\", \"dark\", \"steel\", \"fairy\"\n",
    "]\n",
    "\n",
    "type_to_idx = {t: i for i, t in enumerate(type_list)}\n",
    "\n",
    "# Convertir le DataFrame précédent en matrice NumPy\n",
    "type_matrix = df_type_chart.to_numpy()\n",
    "\n",
    "print(type_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi le vecteur 'type normal' est : [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "type qui attaque = sur la ligne, type qui reçoit = sur la colonne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend en compte le type de chaque pokémon, pour que des corrélations puissent se faire sur les switchs. Donc dans mon embedd j'aurais les types des 5 autres pokés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va tester un premier embedding ! \n",
    "On est obligés d'avoir un vecteur 1D donc il va falloir se dire où est-ce qu'on met quoi :\n",
    "\n",
    "Embedding = ['moves_base_power*moves_dmg_multiplier','pokemon_types']\n",
    "\n",
    "Rq : ne prendra pas en compte les pokemons sans types (l'attaque feu qui fait perdre le type là, bref...). peut-être créer une 19ème colonne ? colonne No_type genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonctions nécessaires\n",
    "def obtain_one_hot_vector_type(p) :\n",
    "    \"\"\"renvoie le type du pokemon au format one-hot encoding\n",
    "    entrée : poke_env.environment.pokemon.Pokemon\n",
    "    sortie : np.array, de longueur fixée 18\"\"\"\n",
    "    vec = np.zeros(18)\n",
    "\n",
    "    if p.type_1 : \n",
    "        vec[type_to_idx[p.type_1.name.lower()]] = 1.0\n",
    "    if p.type_2 :\n",
    "        vec[type_to_idx[p.type_2.name.lower()]] = 1.0\n",
    "    return vec\n",
    "\n",
    "def obtain_pokemon_types(battle):\n",
    "\n",
    "    # Encode ta team\n",
    "    vectors_my_team = [\n",
    "        obtain_one_hot_vector_type(p) if not p.fainted else np.zeros(len(type_to_idx), dtype=np.float32)\n",
    "        for _, p in battle.team.items()\n",
    "    ]\n",
    "    while len(vectors_my_team) < 6:\n",
    "        vectors_my_team.append(np.zeros(len(type_to_idx), dtype=np.float32))\n",
    "    my_team_type = np.concatenate(vectors_my_team)\n",
    "\n",
    "    # Encode la team adverse\n",
    "    vectors_opponent_team = [\n",
    "        obtain_one_hot_vector_type(p) if not p.fainted else np.zeros(len(type_to_idx), dtype=np.float32)\n",
    "        for _, p in battle.opponent_team.items()\n",
    "    ]\n",
    "    while len(vectors_opponent_team) < 6:\n",
    "        vectors_opponent_team.append(np.zeros(len(type_to_idx), dtype=np.float32))\n",
    "    opponent_team_type = np.concatenate(vectors_opponent_team)\n",
    "\n",
    "    # Concatène les deux parties\n",
    "    pokemon_types = np.concatenate([my_team_type, opponent_team_type])\n",
    "    \n",
    "    return pokemon_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium.spaces import Space, Box\n",
    "from poke_env.player import Gen8EnvSinglePlayer\n",
    "from poke_env.data import GenData\n",
    "import numpy as np\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "import torch\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "# Initialiser GenData pour la génération souhaitée (par exemple, génération 8)\n",
    "gen_data = GenData.from_gen(8)\n",
    "\n",
    "# Accéder au tableau des types\n",
    "type_chart = gen_data.type_chart\n",
    "\n",
    "\n",
    "class embedding_Player(Gen8EnvSinglePlayer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.action_space = Discrete(9)  # ✅ attribut classique\n",
    "    \n",
    "    #Toujours mêmes valeurs de reward\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                pokemon_types,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = (\n",
    "            [-1] * 4 +          # real power\n",
    "            [0] * 108 +         # my team types\n",
    "            [0] * 108           # opponent team types\n",
    "        )\n",
    "        high = (\n",
    "            [3] * 4 +           # real power\n",
    "            [1] * 108 +         # my team types\n",
    "            [1] * 108           # opponent team types\n",
    "        )\n",
    "\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def action_to_move(self, action: int, battle: AbstractBattle):\n",
    "        order = super().action_to_move(action, battle)\n",
    "        order.dynamax = False  # 🔥 désactive Dynamax pour toutes les actions\n",
    "        return order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DEBUG\n",
    "from poke_env.environment.pokemon import Pokemon\n",
    "\n",
    "# TEST obtain_one_hot_vector_type(p) ###\n",
    "p = Pokemon(gen=8, species=\"abomasnow\")\n",
    "#print(type(p))\n",
    "#print(p.species)    # 'abomasnow'\n",
    "#print((p.type_1.name.lower()))   # 'grass'\n",
    "#print(p.type_2)\n",
    "\n",
    "vec = np.zeros(18)\n",
    "\n",
    "if p.type_1 : \n",
    "    vec[type_to_idx[p.type_1.name.lower()]] = 1.0\n",
    "if p.type_2 :\n",
    "    vec[type_to_idx[p.type_2.name.lower()]] = 1.0\n",
    "\n",
    "#print(vec)\n",
    "\n",
    "\n",
    "# TEST obtain_pokemon_types(battle) ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poke_env.player.random_player import RandomPlayer\n",
    "\n",
    "class NoDynamaxRandomPlayer(RandomPlayer):\n",
    "    def choose_move(self, battle):\n",
    "        choice = super().choose_move(battle)\n",
    "        if choice.dynamax:\n",
    "            choice.dynamax = False  # désactive l'option\n",
    "        return choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRAINING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opponent = NoDynamaxRandomPlayer(battle_format=\"gen8randombattle\")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# instanciation du player\n",
    "train_env_raw = embedding_Player(\n",
    "    battle_format=\"gen8randombattle\",\n",
    "    opponent=RandomPlayer(battle_format=\"gen8randombattle\"),\n",
    "    start_challenging=True\n",
    ")\n",
    "\n",
    "# wrap dans DummyVecEnv (SB3 attend un vecteur d’envs, même pour un seul)\n",
    "train_env = DummyVecEnv([lambda: train_env_raw])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Réseau perceptron à une couche cachée, sortie linéaire, f activation = Relu,\n",
    "class DQNModel(nn.Module):\n",
    "    def __init__(self, input_dim, n_actions):\n",
    "        super(DQNModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Si ton env est déjà Gym-compatible (comme avec poke-env Gym wrapper)\n",
    "env = train_env\n",
    "\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=2.5e-4,\n",
    "    buffer_size=10000,\n",
    "    learning_starts=1000,\n",
    "    batch_size=32,\n",
    "    gamma=0.5,\n",
    "    train_freq=1,\n",
    "    target_update_interval=1,\n",
    "    exploration_fraction=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    policy_kwargs=dict(activation_fn=nn.ReLU, net_arch=[128, 64])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class CustomTQDMCallback(BaseCallback):\n",
    "    def __init__(self, total_timesteps, check_freq=500, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        self.progress_bar = tqdm(total=self.total_timesteps, desc=\"📊 Training progress\")\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        # Avance la barre\n",
    "        if self.progress_bar:\n",
    "            self.progress_bar.update(1)\n",
    "\n",
    "        # Affichage toutes les X étapes\n",
    "        if self.n_calls % self.check_freq == 0 and self.verbose:\n",
    "            self.progress_bar.set_postfix_str(f\"Timesteps: {self.num_timesteps}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        if self.progress_bar:\n",
    "            self.progress_bar.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e3332fd96d4e6694f0ffa7df4726ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "📊 Training progress:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 50000\n",
    "callback = CustomTQDMCallback(total_timesteps = steps, check_freq=1000, verbose=1)\n",
    "model.learn(\n",
    "    total_timesteps=steps,\n",
    "    callback=callback\n",
    ")\n",
    "model.save(\"embedding_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TEST***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "class EmbeddingTestPlayer(Gen8EnvSinglePlayer):\n",
    "\n",
    "    def __init__(self, model_path=\"embedding_1\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "\n",
    "        #Toujours mêmes valeurs de reward\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                pokemon_types,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = (\n",
    "            [-1] * 4 +          # real power\n",
    "            [0] * 108 +         # my team types\n",
    "            [0] * 108           # opponent team types\n",
    "        )\n",
    "        high = (\n",
    "            [3] * 4 +           # real power\n",
    "            [1] * 108 +         # my team types\n",
    "            [1] * 108           # opponent team types\n",
    "        )\n",
    "\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def action_to_move(self, action, battle):\n",
    "        moves = battle.available_moves\n",
    "        switches = battle.available_switches\n",
    "        total_actions = len(moves) + len(switches)\n",
    "\n",
    "        #print(f\"🔢 DQN → action={action} | #moves={len(moves)} | #switches={len(switches)} | total={total_actions}\")\n",
    "\n",
    "        if 0 <= action < len(moves):\n",
    "            return self.create_order(moves[action])\n",
    "        elif len(moves) <= action < total_actions:\n",
    "            return self.create_order(switches[action - len(moves)])\n",
    "        else:\n",
    "            #print(\"❌ Action hors bornes ! Fallback sur move aléatoire\")\n",
    "            return self.choose_random_move(battle)\n",
    "        \n",
    "    def predict(self, obs):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        q_values = self.model.q_net(obs_tensor)\n",
    "        print(f\"📊 Q-values : {q_values.detach().numpy().flatten()}\")\n",
    "        action = int(torch.argmax(q_values).item())\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle chargé depuis embedding_1\n"
     ]
    }
   ],
   "source": [
    "opponent = NoDynamaxRandomPlayer(battle_format=\"gen8randombattle\")\n",
    "eval_env = EmbeddingTestPlayer(\n",
    "    battle_format=\"gen8randombattle\", opponent=opponent, start_challenging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a47f9aebfe45c18ae64d407df1f723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 53 victoires sur 100 matchs\n",
      "🎯 Reward moyen : 2.27\n"
     ]
    }
   ],
   "source": [
    "n_eval_episodes = 100\n",
    "rewards = []\n",
    "wins = 0\n",
    "\n",
    "obs, _ = eval_env.reset()\n",
    "for _ in tqdm(range(n_eval_episodes)):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = eval_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        total_reward += reward\n",
    "        if done and reward > 0:\n",
    "            wins += 1\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    obs, _ = eval_env.reset()\n",
    "\n",
    "print(f\"✅ {wins} victoires sur {n_eval_episodes} matchs\")\n",
    "print(f\"🎯 Reward moyen : {sum(rewards) / len(rewards):.2f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Embedding = ['moves_base_power*moves_dmg_multiplier','pokemon_types','pokemon_stats']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) On va rajouter les talents d'immunité. On va rajouter un case pour les talents qui donnent des immunités, voila on fait ça à la mano pas grave (if ability in list_immunies_abilities ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VS me\n",
    "from DQ_simple import DQ_simple \n",
    "class DQ_simpleemb1(DQ_simple) :\n",
    "    def __init__(self, model_path = \"embedding_1\", battle_format=\"gen8randombattle\"):\n",
    "        super().__init__(battle_format=battle_format)\n",
    "        \n",
    "        self.model = DQN.load(model_path, device=\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        print(\"📥 Modèle DQN chargé :\", self.model)\n",
    "    \n",
    "    def embed_battle(self, battle )  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "            moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        #Pokemon types  \n",
    "        pokemon_types = obtain_pokemon_types(battle)\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                pokemon_types,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def choose_move(self, battle):\n",
    "        print(\"👉 choose_move appelée !\")\n",
    "        # 🔍 Debug : Voir les moves disponibles\n",
    "        print(f\"🔍 Moves disponibles : {[move.id for move in battle.available_moves]}\")\n",
    "\n",
    "        # Obtenir l'observation de l'état du combat\n",
    "        obs = self.embed_battle(battle)\n",
    "        print(\"📊 Observation de l'état :\", obs)\n",
    "\n",
    "        # Transformer en format PyTorch\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        print(\"📊 Tensor pour le modèle :\", obs_tensor)\n",
    "\n",
    "        # Prédire l'action avec le modèle DQN\n",
    "        action = int(self.model.predict(obs_tensor, deterministic=True)[0])\n",
    "        print(\"🎯 Action choisie par DQN :\", action)\n",
    "        if 0 <= action < len(battle.available_moves):\n",
    "            move = battle.available_moves[action]\n",
    "            print(f\"✅ Move choisi : {move.id}\")\n",
    "\n",
    "            order = self.create_order(move)\n",
    "            print(f\"📤 Ordre créé : {order}\")  # Debug : voir l'ordre exact généré\n",
    "\n",
    "            return order\n",
    "        else:\n",
    "            print(f\"❌ Action {action} invalide, on joue un move aléatoire !\")\n",
    "            return self.choose_random_move(battle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (showdown_3)",
   "language": "python",
   "name": "showdown_3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "455d2c1a4ef8d735c62ff6b7867677aa8f5a8db787748daaa4d34b19b9911963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
