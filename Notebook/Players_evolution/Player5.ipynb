{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouveaux concepts : \n",
    "-\n",
    "\n",
    "- Utiliser les mots les tokens en entrée du réseau, en apprenant un embedding, comme ça on rentre tout d'un coup (toutes les infos)\n",
    "\n",
    "- PPO + LSTM/Transformer comme nouvelle architecture, Q-learning c'est pas ouf car ça nécessite de connaitre tous les states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire actuel : /Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/my_showdown_ai_git\n"
     ]
    }
   ],
   "source": [
    "#1 on se place \n",
    "import os\n",
    "import ipynbname\n",
    "\n",
    "chemin_notebook = ipynbname.path()\n",
    "dossier_notebook = os.path.dirname(chemin_notebook)\n",
    "os.chdir(dossier_notebook)\n",
    "os.chdir('../..')\n",
    "print(\"Répertoire actuel :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poke_env.player.random_player import RandomPlayer\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import json\n",
    "from poke_env.environment.pokemon import Pokemon\n",
    "import poke_env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from poke_env.data import GenData\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "from poke_env.player.random_player import RandomPlayer\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from poke_env.player import Gen4EnvSinglePlayer\n",
    "from poke_env.data import GenData\n",
    "import torch\n",
    "from gymnasium.spaces import Space, Box, Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atk': 130, 'def': 60, 'hp': 65, 'spa': 75, 'spd': 60, 'spe': 75}\n",
      "None\n",
      "unknown_item\n",
      "{'atk': 130, 'def': 60, 'hp': 65, 'spa': 75, 'spd': 60, 'spe': 75}\n"
     ]
    }
   ],
   "source": [
    "p = Pokemon(gen=4,species= 'absol')\n",
    "print(p.base_stats)\n",
    "print(p.ability)\n",
    "print(p.item)\n",
    "print(p.base_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Players.Player5 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vecteur obs :\n",
    "-\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "battle.all_active_pokemons : renvoie les deux pokémons sur le terrain\n",
    "\n",
    "battle.current_observation : renvoie un sacré truc (détaillé après)\n",
    "\n",
    "-> Contient les PVs et status de chaque pokémon\n",
    "\n",
    "Clés de battle.current_observation :\n",
    "['side_conditions', 'opponent_side_conditions', 'weather', 'fields', 'active_pokemon', 'opponent_active_pokemon', 'team', 'opponent_team', 'events']\n",
    "\n",
    "events a en majorité rien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAJ : tout mettre au format vecteur\n",
    "#MAJ : ajout du padding \n",
    "def ObservedPokemon_to_list_false(pokemon,is_active_pokemon,is_opponent_team) -> list: \n",
    "    # Nom du Pokémon\n",
    "    species = getattr(pokemon, \"species\", \"UNKNOWN\")\n",
    "    species_id = species_to_id[species]\n",
    "    item = getattr(pokemon, \"item\", None)\n",
    "\n",
    "    item_id = item_to_id[item]\n",
    "    p = Pokemon(gen=4,species= species)\n",
    "\n",
    "\n",
    "    # Fraction de vie (float entre 0 et 1)\n",
    "    hp = getattr(pokemon, \"current_hp_fraction\", 0.0) or 0.0\n",
    "\n",
    "    # Types (liste de strings ou [])\n",
    "    types = [p.type_1.name.lower() if p.type_1 else None, p.type_2.name.lower() if p.type_2 else None]\n",
    "    if p.type_1 and p.type_2 :\n",
    "        types = sorted([t for t in types])\n",
    "    type_str = types[0] if types[1] is None else f\"{types[0]}_{types[1]}\"\n",
    "    type_id = types_to_id[type_str]\n",
    "\n",
    "    # Statut (string ou \"NONE\")\n",
    "    status = getattr(pokemon, \"status\", None)\n",
    "    status_str = status.name if status else \"NONE\"\n",
    "    status_to_id = {\n",
    "     'NONE': 0,\n",
    "    'PAR': 1,     # paralysie\n",
    "    'SLP': 2,     # sommeil\n",
    "    'BRN': 3,     # brûlure\n",
    "    'FRZ': 4,     # gel\n",
    "    'PSN': 5,     # poison\n",
    "    'TOX': 6,     # poison grave\n",
    "    'FNT': 7\n",
    "        }\n",
    "    status_id = status_to_id[status_str] \n",
    "\n",
    "    #Boosts\n",
    "    if(is_active_pokemon == 1) :\n",
    "\n",
    "        # Boosts (dict ou [0]*7)\n",
    "        boosts = getattr(pokemon, \"boosts\", None)\n",
    "        boosts_list = list(boosts.values()) if boosts else [0] * 7\n",
    "\n",
    "    # Stats (dict ou [0]*6)\n",
    "    if is_opponent_team == 0 : #Si c'est pas l'équipe adverse :\n",
    "\n",
    "        stats = getattr(pokemon, \"stats\", None)\n",
    "        stat_list = list(stats.values()) if stats else [0] * 6\n",
    "        stats_list = [ np.float32(x / 504) for x in stat_list ]\n",
    "\n",
    "    else : #si c'est l'équipe adverse, on fait autrement\n",
    "        level = p.level if hasattr(p, \"level\") and p.level else 80\n",
    "        hp_stat = floor(((2 * p.base_stats[\"hp\"] + 31 + 84 // 4) * level) / 100) + level + 10\n",
    "        if hp == None : \n",
    "            hp = 1.0\n",
    "            #On rajoute un quasi-normalize, pour aller autour de 1 sans que ça soit trop petit, donc on prend pas l'exemple leuphorie 714 stats en PV avec lvl 100, nature, EVs\n",
    "            \n",
    "        atk = floor((2 * p.base_stats[\"atk\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        def_ = floor((2 * p.base_stats[\"def\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spa = floor((2 * p.base_stats[\"spa\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spd = floor((2 * p.base_stats[\"spd\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spe = floor((2 * p.base_stats[\"spe\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        \n",
    "        stats_list = [hp_stat,np.float32(atk/504),np.float32(def_/504),np.float32(spa/504),np.float32(spd/504),np.float32(spe/504)]\n",
    "    #moovepool\n",
    "    moves_dict = getattr(pokemon, \"moves\", None)\n",
    "    move_names = list(moves_dict.keys()) if moves_dict else []\n",
    "\n",
    "    # Pour avoir toujours 4 valeurs :\n",
    "    while len(move_names) < 4:\n",
    "        move_names.append(\"None\")\n",
    "\n",
    "    move_names_id = [\n",
    "        moves_to_id[x.lower().replace(\" \", \"\")] if x and x.lower() != \"none\" else 0 #Padding 0\n",
    "        for x in move_names\n",
    "        ]\n",
    "        \n",
    "    ability = p.ability\n",
    "    ability_id = ability_to_id[ability] if ability else 0 # Padding 0 \n",
    "        \n",
    "        \n",
    "    if(is_active_pokemon == 1) :\n",
    "\n",
    "        return [\n",
    "            species_id,\n",
    "            item_id,\n",
    "            hp,\n",
    "            ability_id,\n",
    "            type_id,\n",
    "            status_id,\n",
    "            *boosts_list,\n",
    "            *stats_list,\n",
    "            *move_names_id[:4]\n",
    "        ]\n",
    "    else : \n",
    "        return [\n",
    "            species_id,\n",
    "            item_id,\n",
    "            hp,\n",
    "            ability_id,\n",
    "            type_id,\n",
    "            status_id,\n",
    "            *stats_list,\n",
    "            *move_names_id[:4]\n",
    "        ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizer obs : \n",
    "-"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On a tout ce qu'on peut avoir :**\n",
    "\n",
    "pièges posés (pdr, spikes ..)\n",
    "\n",
    "climat\n",
    "\n",
    "notre poké actif avec ses pv, talent, ses stats, ses mooves, son nom (species), ses boosts, ses types, ses status\n",
    "\n",
    "notre team avec ses pv, talent, ses stats, ses mooves, son nom (species), ses types, ses status\n",
    "\n",
    "poké adverse avec ses pv, talent, ses stats, ses mooves, son nom (species), ses boosts, ses types, ses status\n",
    "\n",
    "team adverse avec : ses pv, talent, ses stats, ses mooves, son nom (species), ses boosts, ses types, ses status\n",
    "\n",
    "--> Il nous manquera juste ce qui a été joué par l'adversaire, pour l'instant je passe là-dessus, amsi ça veut dire que notre IA pourra pas s'adapter en fonction du style du joueur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings de :**\n",
    "-\n",
    "objets\n",
    "\n",
    "talents\n",
    "\n",
    "attaques\n",
    "\n",
    "noms species\n",
    "\n",
    "status\n",
    "\n",
    "types\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune ID à 0 pour garder le 0 pour le padding. Tous les dicos commencent à 1 (cf regarder codde en dessous)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 : Status\n",
    "- \n",
    "juste un idx pour chaque statut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 : objets\n",
    "-\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 : Talents\n",
    "-"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 : moves \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/csv/move_to_id.csv\")  # ou le chemin local\n",
    "moves_to_id = dict(zip(df[\"move\"], df[\"id\"]))\n",
    "moves_to_id[\"hiddenpower\"] = 186\n",
    "for i in moves_to_id.keys() :\n",
    "    moves_to_id[i] = moves_to_id[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aerialace': 1, 'aeroblast': 2, 'agility': 3, 'airslash': 4, 'aquajet': 5, 'aquatail': 6, 'aromatherapy': 7, 'aurasphere': 8, 'batonpass': 9, 'bellydrum': 10, 'bite': 11, 'blizzard': 12, 'bodyslam': 13, 'bravebird': 14, 'brickbreak': 15, 'bugbite': 16, 'bugbuzz': 17, 'bulkup': 18, 'bulletpunch': 19, 'calmmind': 20, 'chatter': 21, 'closecombat': 22, 'counter': 23, 'crabhammer': 24, 'crosschop': 25, 'crunch': 26, 'curse': 27, 'darkpulse': 28, 'darkvoid': 29, 'destinybond': 30, 'discharge': 31, 'doubleedge': 32, 'dracometeor': 33, 'dragonclaw': 34, 'dragondance': 35, 'dragonpulse': 36, 'drainpunch': 37, 'drillpeck': 38, 'dynamicpunch': 39, 'earthpower': 40, 'earthquake': 41, 'encore': 42, 'energyball': 43, 'eruption': 44, 'explosion': 45, 'extremespeed': 46, 'facade': 47, 'fakeout': 48, 'fireblast': 49, 'firefang': 50, 'firepunch': 51, 'flamethrower': 52, 'flareblitz': 53, 'flashcannon': 54, 'focusblast': 55, 'focuspunch': 56, 'gigaimpact': 57, 'glare': 58, 'grassknot': 59, 'gunkshot': 60, 'hammerarm': 61, 'haze': 62, 'headbutt': 63, 'headsmash': 64, 'healbell': 65, 'healingwish': 66, 'heatwave': 67, 'hiddenpowerelectric': 68, 'hiddenpowerfighting': 69, 'hiddenpowerfire': 70, 'hiddenpowerflying': 71, 'hiddenpowergrass': 72, 'hiddenpowerground': 73, 'hiddenpowerice': 74, 'hiddenpowerpsychic': 75, 'hiddenpowerrock': 76, 'highjumpkick': 77, 'hydropump': 78, 'hypervoice': 79, 'hypnosis': 80, 'icebeam': 81, 'icefang': 82, 'icepunch': 83, 'iceshard': 84, 'ironhead': 85, 'irontail': 86, 'judgment': 87, 'knockoff': 88, 'lavaplume': 89, 'leafblade': 90, 'leafstorm': 91, 'leechseed': 92, 'lovelykiss': 93, 'lowkick': 94, 'machpunch': 95, 'megahorn': 96, 'metalburst': 97, 'meteormash': 98, 'milkdrink': 99, 'mirrorcoat': 100, 'moonlight': 101, 'morningsun': 102, 'nastyplot': 103, 'nightshade': 104, 'nightslash': 105, 'outrage': 106, 'overheat': 107, 'painsplit': 108, 'payback': 109, 'poisonjab': 110, 'powergem': 111, 'powerwhip': 112, 'protect': 113, 'psychic': 114, 'psychoboost': 115, 'psychocut': 116, 'pursuit': 117, 'quickattack': 118, 'raindance': 119, 'rapidspin': 120, 'recover': 121, 'refresh': 122, 'rest': 123, 'return': 124, 'roar': 125, 'rockblast': 126, 'rockpolish': 127, 'rockslide': 128, 'roost': 129, 'sacredfire': 130, 'seedbomb': 131, 'seedflare': 132, 'seismictoss': 133, 'selfdestruct': 134, 'shadowball': 135, 'shadowclaw': 136, 'shadowsneak': 137, 'signalbeam': 138, 'skyuppercut': 139, 'slackoff': 140, 'sleeppowder': 141, 'sleeptalk': 142, 'sludgebomb': 143, 'softboiled': 144, 'solarbeam': 145, 'spacialrend': 146, 'spikes': 147, 'spore': 148, 'stealthrock': 149, 'stoneedge': 150, 'stunspore': 151, 'substitute': 152, 'suckerpunch': 153, 'sunnyday': 154, 'superfang': 155, 'superpower': 156, 'surf': 157, 'switcheroo': 158, 'swordsdance': 159, 'synthesis': 160, 'tailglow': 161, 'taunt': 162, 'thunder': 163, 'thunderbolt': 164, 'thunderfang': 165, 'thunderpunch': 166, 'thunderwave': 167, 'toxic': 168, 'toxicspikes': 169, 'transform': 170, 'triattack': 171, 'trick': 172, 'trickroom': 173, 'uturn': 174, 'vacuumwave': 175, 'volttackle': 176, 'waterfall': 177, 'waterspout': 178, 'weatherball': 179, 'whirlwind': 180, 'willowisp': 181, 'wish': 182, 'woodhammer': 183, 'xscissor': 184, 'yawn': 185, 'zenheadbutt': 186, 'hiddenpower': 187}\n"
     ]
    }
   ],
   "source": [
    "print(moves_to_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 : Species\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/csv/species_to_id.csv\")  # ou le chemin local\n",
    "species_to_id = dict(zip(df[\"species\"], df[\"id\"]))\n",
    "for i in species_to_id.keys() :\n",
    "    species_to_id[i] = species_to_id[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_id[\"gastrodoneast\"] = 100\n",
    "species_to_id[\"gastrodonwest\"] = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout de tous les types de unown\n",
    "for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "    species_to_id[f\"unown{c}\"] = species_to_id[\"unown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_id[\"unownquestion\"] = species_to_id[\"unown\"]\n",
    "species_to_id[\"unownexclamation\"] = species_to_id[\"unown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(species_to_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 : Types\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Players.Player5 import types\n",
    "\n",
    "# Générer les combinaisons mono- et duo-types, sans doublons (ordre alphabétique)\n",
    "type_combos = set()\n",
    "\n",
    "for t in types:\n",
    "    type_combos.add((t,))\n",
    "    for t2 in types:\n",
    "        if t != t2:\n",
    "            type_combos.add(tuple(sorted([t, t2])))\n",
    "\n",
    "# Convertir en string clés\n",
    "combo_keys = [\"_\".join(combo) for combo in sorted(type_combos)]\n",
    "combo_keys.append(\"none\")\n",
    "\n",
    "# Générer le dictionnaire\n",
    "types_to_id = {k: i+1 for i, k in enumerate(combo_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(types_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Players.Player5 import item_to_id, ability_to_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 : side_conditions et weather : \n",
    "-"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va modifier un peu ce qu'on a fait. On va créer une espèce de vecteur one-hot pour les conditions : \n",
    "\n",
    "[\"binaire présence/absence de pièges de roc\", \"spikes\", \"nb spikes\", \"t spikes\", \"nb t spikes\", \"lightscreen\", \"nb tours lightscreen\", \"protection\", \"nb tours protection\", \"tailwind', \"nb tours tailwind\", \"sticky\"] : vecteur de taille 12.\n",
    "\n",
    " Donc on va se servir du dico id pour placer les valeurs aux bons endroits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 : Cache des objets pokemon, plus rapide que de les créer\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from poke_env.environment.pokemon import Pokemon\n",
    "\n",
    "# 1. Charger le fichier\n",
    "with open(\"json/sets.json\", \"r\") as f:\n",
    "    sets_data = json.load(f)\n",
    "\n",
    "# 2. Préremplir le cache\n",
    "POKEMON_CACHE = {}\n",
    "for species in sets_data.keys():\n",
    "    try:\n",
    "        POKEMON_CACHE[species.lower()] = Pokemon(gen=4, species=species)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur pour {species} : {e}\")\n",
    "\n",
    "\n",
    "# Ajouter explicitement toutes les formes d'Unown\n",
    "for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "    POKEMON_CACHE[f\"unown{c}\"] = Pokemon(gen=4, species=\"unown\")\n",
    "POKEMON_CACHE[\"unownquestion\"] = Pokemon(gen=4, species=\"unown\")\n",
    "POKEMON_CACHE[\"unownexclamation\"] = Pokemon(gen=4, species=\"unown\")\n",
    "\n",
    "# Ajouter explicitement les deux formes de Gastrodon\n",
    "POKEMON_CACHE[\"gastrodoneast\"] = Pokemon(gen=4, species=\"gastrodoneast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(POKEMON_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAJ : tout mettre au format vecteur\n",
    "#MAJ : ajout du padding \n",
    "def ObservedPokemon_to_list(pokemon,is_active_pokemon,is_opponent_team) -> list: \n",
    "    # Nom du Pokémon\n",
    "    species = getattr(pokemon, \"species\", \"UNKNOWN\")\n",
    "    species_id = species_to_id[species]\n",
    "    #Norm\n",
    "    species_id_norm = np.float32(species_id/len(species_to_id))\n",
    "\n",
    "    item = getattr(pokemon, \"item\", None)\n",
    "\n",
    "    item_id = item_to_id[item]\n",
    "    item_id_norm = np.float32(item_id/len(item_to_id))\n",
    "\n",
    "    if species.lower() in POKEMON_CACHE:\n",
    "        p = POKEMON_CACHE[species.lower()]\n",
    "    else:\n",
    "        print(f\"[WARN] Espèce inconnue dans le cache : {species}\")\n",
    "        p = Pokemon(gen=4, species=species)  # Fallback (devrait jamais arriver si cache bien rempli)\n",
    "\n",
    "\n",
    "    # Fraction de vie (float entre 0 et 1)\n",
    "    hp = getattr(pokemon, \"current_hp_fraction\", 0.0) or 0.0\n",
    "\n",
    "    # Types (liste de strings ou [])\n",
    "    types = [p.type_1.name.lower() if p.type_1 else None, p.type_2.name.lower() if p.type_2 else None]\n",
    "    if p.type_1 and p.type_2 :\n",
    "        types = sorted([t for t in types])\n",
    "    type_str = types[0] if types[1] is None else f\"{types[0]}_{types[1]}\"\n",
    "    type_id = types_to_id[type_str]\n",
    "    type_id_norm = np.float32(type_id/len(types_to_id))\n",
    "\n",
    "    # Statut (string ou \"NONE\")\n",
    "    status = getattr(pokemon, \"status\", None)\n",
    "    status_str = status.name if status else \"NONE\"\n",
    "    status_to_id = {\n",
    "     'NONE': 0,\n",
    "    'PAR': 1,     # paralysie\n",
    "    'SLP': 2,     # sommeil\n",
    "    'BRN': 3,     # brûlure\n",
    "    'FRZ': 4,     # gel\n",
    "    'PSN': 5,     # poison\n",
    "    'TOX': 6,     # poison grave\n",
    "    'FNT': 7\n",
    "        }\n",
    "    status_id = status_to_id[status_str] \n",
    "    status_id_norm = status_id/len(status_to_id)\n",
    "\n",
    "    #Boosts\n",
    "    if(is_active_pokemon == 1) :\n",
    "\n",
    "        # Boosts (dict ou [0]*7)\n",
    "        boosts = getattr(pokemon, \"boosts\", None)\n",
    "        boosts_list = list(boosts.values()) if boosts else [0] * 7\n",
    "        boosts_list_norm = [np.float32(b / 8) for b in boosts_list]\n",
    "\n",
    "    # Stats (dict ou [0]*6) noramlisées\n",
    "    if is_opponent_team == 0 : #Si c'est pas l'équipe adverse :\n",
    "\n",
    "        stats = getattr(pokemon, \"stats\", None)\n",
    "        stat_list = list(stats.values()) if stats else [0] * 6\n",
    "        stats_list = [np.float32(x / 504) if x is not None else 0.0 for x in stat_list]\n",
    "        #print(f\"DEBUUUUUUUUG VALEUR DE STATS_LIST: {stats_list}\")\n",
    "\n",
    "    else : #si c'est l'équipe adverse, on fait autrement\n",
    "        level = p.level if hasattr(p, \"level\") and p.level else 80\n",
    "        hp_stat = floor(((2 * p.base_stats[\"hp\"] + 31 + 84 // 4) * level) / 100) + level + 10\n",
    "        if hp == None : \n",
    "            hp = 1.0\n",
    "            #On rajoute un quasi-normalize, pour aller autour de 1 sans que ça soit trop petit, donc on prend pas l'exemple leuphorie 714 stats en PV avec lvl 100, nature, EVs\n",
    "            \n",
    "        atk = floor((2 * p.base_stats[\"atk\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        def_ = floor((2 * p.base_stats[\"def\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spa = floor((2 * p.base_stats[\"spa\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spd = floor((2 * p.base_stats[\"spd\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        spe = floor((2 * p.base_stats[\"spe\"] + 31 + 84 // 4) * level / 100 + 5) \n",
    "        if atk is None :\n",
    "            atk = 0\n",
    "        if def_ is None : \n",
    "            def_ = 0\n",
    "        if spa is None : \n",
    "            spa = 0\n",
    "        if spd is None : \n",
    "            spd = 0 \n",
    "        if spe is None : \n",
    "            spe = 0\n",
    "        stats_list = [np.float32(hp_stat/504),np.float32(atk/504),np.float32(def_/504),np.float32(spa/504),np.float32(spd/504),np.float32(spe/504)]\n",
    "        #print(f\"DEBUUUUUUUUG VALEUR DE STATS_LIST: {stats_list}\")\n",
    "    #moovepool\n",
    "    moves_dict = getattr(pokemon, \"moves\", None)\n",
    "    move_names = list(moves_dict.keys()) if moves_dict else []\n",
    "\n",
    "    # Pour avoir toujours 4 valeurs :\n",
    "    while len(move_names) < 4:\n",
    "        move_names.append(\"None\")\n",
    "\n",
    "    move_names_id = [\n",
    "        moves_to_id[x.lower().replace(\" \", \"\")] if x and x.lower() != \"none\" else 0 #Padding 0\n",
    "        for x in move_names\n",
    "        ]\n",
    "    normalized_moves = [np.float32(m / len(moves_to_id)) for m in move_names_id[:4]]\n",
    "        \n",
    "    ability = p.ability\n",
    "    ability_id = ability_to_id[ability] if ability else 0 # Padding 0 \n",
    "    ability_id_norm = np.float32(ability_id/len(ability_to_id))\n",
    "        \n",
    "        \n",
    "    if(is_active_pokemon == 1) :\n",
    "        #on normalise\n",
    "        return [\n",
    "            species_id_norm,\n",
    "            item_id_norm,\n",
    "            hp,\n",
    "            ability_id_norm,\n",
    "            type_id_norm,\n",
    "            status_id_norm,\n",
    "            *boosts_list_norm,\n",
    "            *stats_list,\n",
    "            *normalized_moves\n",
    "        ]\n",
    "    else : \n",
    "        return [\n",
    "            species_id_norm,\n",
    "            item_id_norm,\n",
    "            hp,\n",
    "            ability_id_norm,\n",
    "            type_id_norm,\n",
    "            status_id_norm,\n",
    "            *stats_list,\n",
    "            *normalized_moves\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_team_switches avec les stats, mooves, %hp, status\n",
    "from itertools import chain\n",
    "\n",
    "def get_my_switches_with_all_infos(switches,dict) : \n",
    "\n",
    "    # Dictionnaire contenant les ObservedPokemon (via battle.current_observation.__dict__[\"team\"])\n",
    "    team_obs_dict = dict[\"team\"]\n",
    "\n",
    "    enriched_switches = []\n",
    "\n",
    "    for poke in switches:\n",
    "        # Trouver l'ObservedPokemon correspondant en comparant le species\n",
    "        matched_obs = next(\n",
    "            (obs for obs in team_obs_dict.values()\n",
    "             if hasattr(obs, \"species\") and obs.species == poke.species),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if matched_obs:\n",
    "            enriched_switches += ObservedPokemon_to_list(matched_obs,is_active_pokemon=0,is_opponent_team=0)\n",
    "        else:\n",
    "            # Fallback si non trouvé\n",
    "            enriched_switches += [\"UNKNOWN\", 0.0, \"NONE\"] + [0]*7 + [0]*6\n",
    "\n",
    "    return enriched_switches\n",
    "    \n",
    "def get_opponent_team_with_all_infos(dict,battle) : \n",
    "\n",
    "    # Dictionnaire contenant les ObservedPokemon (via battle.current_observation.__dict__[\"team\"])\n",
    "    team_obs_dict = dict[\"opponent_team\"]\n",
    "    #enlever le pokemon actif adverse\n",
    "    active = battle.opponent_active_pokemon\n",
    "\n",
    "    opponent_team_list = []\n",
    "    for poke in team_obs_dict.values() :\n",
    "        if poke.species != active.species:\n",
    "            opponent_team_list += ObservedPokemon_to_list(poke,is_active_pokemon=0,is_opponent_team=1)\n",
    "\n",
    "\n",
    "    return opponent_team_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de padding. Chaque donnée aura la dimension maximale comme ça on aura un vecteur de taille fixe. Et donc quand le vecteur donnée n'atteint pas len_max, on le complète avec des 0 \n",
    "def pad_list(liste, max_len, pad_value=0.0):\n",
    "    \"\"\"Retourne une liste de longueur max_len,\n",
    "    paddée avec pad_value si besoin.\"\"\"\n",
    "    if len(liste) > max_len :\n",
    "        print(f\"[WARN] La liste d'entrée est plus longue ({len(liste)}) que max_len ({max_len}) — elle va être tronquée.\")\n",
    "    res = list(liste[:max_len])\n",
    "    while len(res) < max_len:\n",
    "        res.append(pad_value)\n",
    "    return res\n",
    "\n",
    "def pad_vector(vector, max_len, pad_value=0.0, dtype=np.float32):\n",
    "    \"\"\"Retourne un np.array de longueur max_len,\n",
    "    paddé avec pad_value si besoin.\"\"\"\n",
    "    arr = np.full(max_len, pad_value, dtype=dtype)\n",
    "    arr[:min(len(vector), max_len)] = vector[:max_len]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour obtenir le weather\n",
    "def get_weather(dict_observation) :\n",
    "    obs_weather = dict_observation[\"weather\"]\n",
    "    if obs_weather:\n",
    "        weather_enum, turns_left = next(iter(obs_weather.items()))\n",
    "    else:\n",
    "        weather_enum, turns_left = None, 0  # ou None, 0 selon ton mapping\n",
    "\n",
    "    weather = [weather_enum, turns_left]\n",
    "    return weather\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector conditons : [\"binaire présence/absence de pièges de roc\", \"spikes\", \"nb spikes\", \"t spikes\", \"nb t spikes\", \"lightscreen\", \"nb tours lightscreen\", \"protection\", \"nb tours protection\", \"tailwind', \"nb tours tailwind\", \"sticky\"] : vecteur de taille 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poke_env.environment.side_condition import SideCondition\n",
    "from Players.Player5 import side_condition_to_id\n",
    "#Fonction pour obtenir les sides conditions\n",
    "#Remarque : au lieu d'appeller ça conditons on pourrait peut-être appeller ça hazard...\n",
    "MAX_LEN_SIDE_CONDITIONS = 12\n",
    "def get_side_conditions(dict_observation,is_my_side) :\n",
    "    vector = [0 for i in range(MAX_LEN_SIDE_CONDITIONS)] #padding déjà fait du coup\n",
    "    if is_my_side :\n",
    "        obs_conditions = dict_observation[\"side_conditions\"]\n",
    "    else : \n",
    "        obs_conditions = dict_observation[\"opponent_side_conditions\"]\n",
    "    \n",
    "    if obs_conditions :\n",
    "        for i in obs_conditions.keys() :\n",
    "            if i== SideCondition.STEALTH_ROCK or i== SideCondition.STICKY_WEB :\n",
    "                id = side_condition_to_id[i]\n",
    "                vector[id] = 1\n",
    "            else :\n",
    "                id = side_condition_to_id[i]\n",
    "                vector[id] = 1\n",
    "                vector[id+1] = obs_conditions[i] #On prend la valeur associée au hazard dans le dico\n",
    "\n",
    "    #On normalise car ce vecteur rentre directement dans le réseau profond sans passer par l'embedding\n",
    "    vector[2] = vector[2]/3 # 3 spikes maximum\n",
    "    vector[4] = vector[4]/2 # 2 t spikes maximum\n",
    "    vector[6] = vector[6]/8 # 8 tours de screen max\n",
    "    vector[8] = vector[8]/8 # 8 tours de screen max\n",
    "    vector[10] = vector[10]/4 # 4 tours de tailwind max\n",
    "\n",
    "    return vector\n",
    "\n",
    "#Verif : j'ai vérifié en lançant des games que ça marchait et ça marchait bien. J'ai pu voir pdr et spikes posé, avec 1 seul spike et c'était bien capturé par ma fonction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Savoir si je suis lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_my_pokemon_locked(dict_observation) :\n",
    "    poke = dict_observation.get(\"active_pokemon\", None)\n",
    "    if poke is None:\n",
    "        return 0  # Pas de pokémon actif, donc pas locké\n",
    "    item = getattr(poke, \"item\",None)\n",
    "    is_choice = item in {\"choiceband\", \"choicescarf\", \"choicespecs\"}\n",
    "\n",
    "    is_encored = False\n",
    "    if hasattr(poke, \"volatiles\") and \"encore\" in getattr(poke, \"volatiles\", {}):\n",
    "        is_encored = True\n",
    "    elif hasattr(poke, \"encore_turns\") and getattr(poke, \"encore_turns\", 0) > 0:\n",
    "        is_encored = True\n",
    "\n",
    "    return int(is_choice or is_encored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Players.Player5 import weather_to_id\n",
    "\n",
    "#MAX_LEN_SIDE_CONDITIONS = 12, déjà def plus haut\n",
    "MAX_LEN_WEATHER = 2\n",
    "LEN_POKE = 16 #C'était pas la bonne valeur car on avait rajouté une feature item donc ça faisait une len de 17, mais vu qu'en pratique on a jamais utilisé \n",
    "#ça on a pas vu l'erreur. Bref tkt pas pour les dims c'est 16 pour ceux de la team et 23 pour le poke actif \n",
    "LEN_ACTIVE_POKE = 23\n",
    "MAX_LEN_TEAM_SWITCHES = 80 # 16x5 , cohérent\n",
    "class adapted_obs_as_readable_str : \n",
    "    def __init__(self,battle) :\n",
    "        self.dict_observation = battle.current_observation.__dict__ \n",
    "        #et stocker l'état précédent ? Pour l'instant on passe\n",
    "        self.side_conditions = get_side_conditions(self.dict_observation,1) #padding et normalisation déjà réalisés dedans\n",
    "\n",
    "        self.opponent_side_conditions = get_side_conditions(self.dict_observation,0) # pareil padding et normalisation déjà réalisés\n",
    "\n",
    "        self.weather = get_weather(self.dict_observation)\n",
    "        self.weather[0] = weather_to_id[self.weather[0]]/4\n",
    "        self.weather = pad_list(self.weather,max_len =MAX_LEN_WEATHER) \n",
    "\n",
    "        self.active_pokemon =list( ObservedPokemon_to_list(self.dict_observation[\"active_pokemon\"],is_active_pokemon=1,is_opponent_team=0))\n",
    "        self.my_team_switches = list(get_my_switches_with_all_infos(battle.available_switches,self.dict_observation))\n",
    "        self.opponent_active_pokemon = list(ObservedPokemon_to_list(self.dict_observation[\"opponent_active_pokemon\"],is_active_pokemon=1,is_opponent_team=1)) #à 1 car on veut savoir si il est boosté\n",
    "        \n",
    "        #Equipe adverse sans le pokemon actif \n",
    "        self.opponent_team = list(get_opponent_team_with_all_infos(self.dict_observation,battle))\n",
    "        #Fin équipe adverse \n",
    "        self.output =   [\"side_conditions\"] + self.side_conditions + [\"opponent_side_conditions\"] + self.opponent_side_conditions + [\"weather\"] + self.weather + [\"active_pokemon\"] + self.active_pokemon + [\"my_team_switches\"] + self.my_team_switches + [\"opponent_active_pokemon\"] + self.opponent_active_pokemon + [\"opponent_team\"] + self.opponent_team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on redéfinit obs, pour cette fois-ci avoir tout au format vecteur, et plus rien en str\n",
    "#MAJ : on le met à jour avec l'obs débuggé str\n",
    "MAX_LEN_WEATHER = 2\n",
    "LEN_POKE = 16 \n",
    "LEN_ACTIVE_POKE = 23 \n",
    "MAX_LEN_TEAM_SWITCHES = 80 #\n",
    "IDX_ACTION_SPACE_SIZE = 232\n",
    "class adapted_obs :\n",
    "    def __init__(self,battle) :\n",
    "        self.dict_observation = battle.current_observation.__dict__ \n",
    "        #et stocker l'état précédent ? Pour l'instant on passe\n",
    "        self.side_conditions = np.array(get_side_conditions(self.dict_observation,1),dtype=np.float32) # padding et normalisation déjà réalisés dedans\n",
    "\n",
    "        self.opponent_side_conditions = np.array(get_side_conditions(self.dict_observation,0),dtype=np.float32) # padding et normalisation déjà réalisés dedans \n",
    "        \n",
    "        self.weather = get_weather(self.dict_observation)\n",
    "        self.weather[0] = weather_to_id[self.weather[0]]/4\n",
    "        self.weather = pad_list(self.weather,max_len =MAX_LEN_WEATHER) # padding \n",
    "        self.weather = np.array(self.weather,dtype=np.float32)\n",
    "\n",
    "        self.active_pokemon =np.array( ObservedPokemon_to_list(self.dict_observation[\"active_pokemon\"],is_active_pokemon=1,is_opponent_team=0),dtype=np.float32)\n",
    "        self.my_team_switches = np.array(get_my_switches_with_all_infos(battle.available_switches,self.dict_observation),dtype=np.float32)\n",
    "        #Calcul du action space avant le padding\n",
    "        lock = is_my_pokemon_locked(self.dict_observation)\n",
    "        self.action_space_size = len(self.my_team_switches)//16 + lock*1 + (1-lock)*4 #SI lock alors 1 move, sinon 4\n",
    "        self.action_space_size = self.action_space_size / 9\n",
    "        self.action_space_size = np.array([self.action_space_size], dtype=np.float32)\n",
    "        self.my_team_switches = pad_vector(self.my_team_switches,max_len= MAX_LEN_TEAM_SWITCHES)\n",
    "        self.opponent_active_pokemon = np.array(ObservedPokemon_to_list(self.dict_observation[\"opponent_active_pokemon\"],is_active_pokemon=1,is_opponent_team=1),dtype=np.float32) #à 1 car on veut savoir si il est boosté\n",
    "        \n",
    "        #Equipe adverse sans le pokemon actif \n",
    "        self.opponent_team = np.array(get_opponent_team_with_all_infos(self.dict_observation,battle),dtype=np.float32)\n",
    "        self.opponent_team = pad_vector(self.opponent_team ,max_len= MAX_LEN_TEAM_SWITCHES)\n",
    "        #Fin équipe adverse \n",
    "        self.output = np.concatenate([\n",
    "            self.side_conditions, #Fonctionnel\n",
    "            self.opponent_side_conditions, #Fonctionnel\n",
    "            self.weather, #Fonctionnel\n",
    "            self.active_pokemon, #Fonctionnel\n",
    "            self.my_team_switches, #Fonctionnel\n",
    "            self.opponent_active_pokemon, #Fonctionnel\n",
    "            self.opponent_team, #Fonctionnel\n",
    "            self.action_space_size #Fonctionnel\n",
    "        ])\n",
    "\n",
    "#LEN(obs) = 233"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclus dans ObservedPoke : hp, types, status, moves, ability, stats.\n",
    "Non inclus : side_conditions, opponent_side_conditions, weather.\n",
    "Les tailles sont écrites ci-dessous"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weather : OK\n",
    "side_conditions : OK\n",
    "item : OK\n",
    "le reste : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poke_env.player.random_player import RandomPlayer\n",
    "\n",
    "class MyEnvPlayer(Gen4EnvSinglePlayer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "         super().__init__(*args, **kwargs)\n",
    "     \n",
    "    def embed_battle(self, battle) -> np.ndarray: #renvoie obs\n",
    "        #if battle.turn == 1 : \n",
    "        obs = adapted_obs_as_readable_str(battle) \n",
    "        obs = obs.output\n",
    "        #else : \n",
    "            #obs = obs.update(battle)\n",
    "            \n",
    "        return obs\n",
    "\n",
    "    def calc_reward(self, current_battle,last_battle) -> float:\n",
    "        # Reward simple : +1 si l'adversaire est KO, -1 si toi tu l'es\n",
    "        reward = 0\n",
    "        if last_battle.opponent_active_pokemon and current_battle.opponent_active_pokemon.fainted:\n",
    "            reward += 1\n",
    "        if last_battle.active_pokemon and current_battle.active_pokemon.fainted:\n",
    "            reward -= 1\n",
    "        return reward\n",
    "\n",
    "    def describe_embedding(self) -> tuple:\n",
    "        return (2,), np.float32  # 2 valeurs float (my HP, opp HP)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = RandomPlayer(battle_format=\"gen4randombattle\")\n",
    "\n",
    "# Ton agent (env Gym-compatible)\n",
    "env = MyEnvPlayer(battle_format=\"gen4randombattle\", opponent=opponent)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['side_conditions', 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 'opponent_side_conditions', 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 'weather', 0.0, 0, 'active_pokemon', np.float32(0.80981594), np.float32(0.13636364), 1.0, np.float32(0.0), np.float32(0.6038961), 0.0, np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.52380955), np.float32(0.16666667), np.float32(0.3888889), np.float32(0.46626985), np.float32(0.45039684), np.float32(0.34126985), np.float32(0.34759358), np.float32(0.8930481), np.float32(0.021390375), np.float32(0.6898396), 'my_team_switches', np.float32(0.5889571), np.float32(0.13636364), 1.0, np.float32(0.3627451), np.float32(0.6363636), 0.0, np.float32(0.515873), np.float32(0.19246031), np.float32(0.46825397), np.float32(0.41468254), np.float32(0.35912699), np.float32(0.34126985), np.float32(0.6898396), np.float32(0.8983957), np.float32(0.021390375), np.float32(0.8395722), np.float32(0.2638037), np.float32(0.13636364), 1.0, np.float32(0.0882353), np.float32(0.74025977), 0.0, np.float32(0.61507934), np.float32(0.34325397), np.float32(0.3968254), np.float32(0.53373015), np.float32(0.32738096), np.float32(0.28968254), np.float32(1.0), np.float32(0.6096257), np.float32(0.486631), np.float32(0.85561496), np.float32(0.5736196), np.float32(0.06818182), 1.0, np.float32(0.0), np.float32(0.9935065), 0.0, np.float32(0.5575397), np.float32(0.38492063), np.float32(0.3690476), np.float32(0.47619048), np.float32(0.3690476), np.float32(0.26190478), np.float32(0.4331551), np.float32(0.8395722), np.float32(0.22994652), np.float32(0.2620321), np.float32(0.70858896), np.float32(0.1590909), 1.0, np.float32(0.0), np.float32(0.103896104), 0.0, np.float32(0.45833334), np.float32(0.48015872), np.float32(0.3888889), np.float32(0.25396827), np.float32(0.32936507), np.float32(0.28373015), np.float32(0.85026735), np.float32(0.101604275), np.float32(0.0855615), np.float32(0.6898396), np.float32(0.702454), np.float32(0.13636364), 1.0, np.float32(0.627451), np.float32(0.76623374), 0.0, np.float32(0.5575397), np.float32(0.45833334), np.float32(0.4940476), np.float32(0.26190478), np.float32(0.29761904), np.float32(0.33333334), np.float32(0.79679143), np.float32(0.21925133), np.float32(0.8983957), np.float32(0.64171124), 'opponent_active_pokemon', np.float32(0.5429448), np.float32(0.0), 1.0, np.float32(0.38235295), np.float32(0.64285713), 0.0, np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5595238), np.float32(0.35119048), np.float32(0.35119048), np.float32(0.5297619), np.float32(0.5297619), np.float32(0.5297619), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), 'opponent_team']\n"
     ]
    }
   ],
   "source": [
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['side_conditions', 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 'opponent_side_conditions', 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 'weather', 0.0, 0, 'active_pokemon', np.float32(0.2791411), np.float32(0.13636364), 1.0, np.float32(0.21568628), np.float32(0.4935065), 0.0, np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.5456349), np.float32(0.4940476), np.float32(0.32936507), np.float32(0.46031746), np.float32(0.515873), np.float32(0.34920636), np.float32(0.47593582), np.float32(0.8983957), np.float32(0.973262), np.float32(0.6042781), 'my_team_switches', np.float32(0.08895706), np.float32(0.13636364), 1.0, np.float32(0.068627454), np.float32(0.097402595), 0.0, np.float32(0.5277778), np.float32(0.51785713), np.float32(0.43452382), np.float32(0.33333334), np.float32(0.3670635), np.float32(0.24801587), np.float32(0.64171124), np.float32(0.80213904), np.float32(0.21925133), np.float32(0.98395723), np.float32(0.72392637), np.float32(0.1590909), 1.0, np.float32(0.48039216), np.float32(0.7077922), 0.0, np.float32(0.5714286), np.float32(0.3234127), np.float32(0.4047619), np.float32(0.4047619), np.float32(0.4047619), np.float32(0.4047619), np.float32(0.85561496), np.float32(0.021390375), np.float32(0.7058824), np.float32(0.21390374), np.float32(0.797546), np.float32(0.77272725), 1.0, np.float32(0.27450982), np.float32(0.6038961), 0.0, np.float32(0.45039684), np.float32(0.3611111), np.float32(0.28174603), np.float32(0.25), np.float32(0.25), np.float32(0.48809522), np.float32(0.631016), np.float32(0.93048126), np.float32(0.07486631), np.float32(0.2513369), np.float32(0.70552146), np.float32(0.09090909), 1.0, np.float32(0.5), np.float32(0.7077922), 0.0, np.float32(0.5), np.float32(0.37301588), np.float32(0.30753967), np.float32(0.44047618), np.float32(0.375), np.float32(0.49007937), np.float32(0.684492), np.float32(1.0), np.float32(0.29411766), np.float32(0.486631), np.float32(0.7791411), np.float32(0.13636364), 1.0, np.float32(0.0), np.float32(0.8051948), 0.0, np.float32(0.5218254), np.float32(0.37896827), np.float32(0.7619048), np.float32(0.2797619), np.float32(0.31150794), np.float32(0.19642857), np.float32(0.6042781), np.float32(0.45454547), np.float32(0.21925133), np.float32(0.8983957), 'opponent_active_pokemon', np.float32(0.18404908), np.float32(0.0), 1.0, np.float32(0.38235295), np.float32(0.9350649), 0.0, np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.79761904), np.float32(0.39087301), np.float32(0.58928573), np.float32(0.4107143), np.float32(0.62896824), np.float32(0.45039684), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), 'opponent_team']\n"
     ]
    }
   ],
   "source": [
    "############ CODE POUR DEROULER TOUT UN MATCH ###########\n",
    "\n",
    "# Adversaire\n",
    "opponent = RandomPlayer(battle_format=\"gen4randombattle\")\n",
    "\n",
    "# Ton agent (env Gym-compatible)\n",
    "env = MyEnvPlayer(battle_format=\"gen4randombattle\", opponent=opponent)\n",
    "\n",
    "# Lancer un match\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle (embedding + réseau profond) :\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DEFINIR MODELE ##################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "IDX_ACTION_SPACE_SIZE = 232\n",
    "LEN_POKE = 16 \n",
    "LEN_ACTIVE_POKE = 23 \n",
    "LEN_WEATHER = 2\n",
    "LEN_CONDITIONS = 12\n",
    "#Réseau perceptron à deux couche cachée, sortie linéaire, f activation = Relu,\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self, input_dim, n_actions):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, n_actions)\n",
    "        #Embedding\n",
    "        self.item_embedding = nn.Embedding(\n",
    "        num_embeddings=len(item_to_id) + 1,  # nombre total d'objets\n",
    "        embedding_dim=8                # dimension du vecteur d'embedding\n",
    "        )\n",
    "        self.ability_embedding = nn.Embedding(\n",
    "        num_embeddings=len(ability_to_id)+1,\n",
    "        embedding_dim= 8\n",
    "        )\n",
    "        self.moves_embedding = nn.Embedding(\n",
    "        num_embeddings=len(moves_to_id)+1,\n",
    "        embedding_dim= 16\n",
    "        )\n",
    "        self.species_embedding = nn.Embedding(\n",
    "        num_embeddings=len(species_to_id)+1,\n",
    "        embedding_dim= 32\n",
    "        )\n",
    "        self.types_embedding = nn.Embedding(\n",
    "        num_embeddings=len(types_to_id)+1,\n",
    "        embedding_dim= 8\n",
    "        )\n",
    "    ####Renvoies le vecteur embedding pour un pokémon####\n",
    "    def embed_pokemon(self, poke_vec, is_active_poke):\n",
    "        species  = torch.tensor(int(poke_vec[0]), dtype=torch.long)\n",
    "        item     = torch.tensor(int(poke_vec[1]), dtype=torch.long)\n",
    "        ability  = torch.tensor(int(poke_vec[3]), dtype=torch.long)\n",
    "        types    = torch.tensor(int(poke_vec[4]), dtype=torch.long)\n",
    "        poke_vec_tensor = torch.tensor(poke_vec, dtype=torch.float32)\n",
    "\n",
    "        if is_active_poke == 0:\n",
    "            moves = torch.tensor(poke_vec[11:15], dtype=torch.long)\n",
    "            mid_vec = poke_vec_tensor[5:11]  # 6 valeurs (status + stats)\n",
    "        else:\n",
    "            moves = torch.tensor(poke_vec[18:22], dtype=torch.long)\n",
    "            mid_vec = poke_vec_tensor[5:18]  # 13 valeurs (status + boosts + stats)\n",
    "        #print(f\"species: {species}, item: {item}, ability: {ability}, types: {types}, moves: {moves}\")\n",
    "\n",
    "        species_emb = self.species_embedding(species)\n",
    "        item_emb    = self.item_embedding(item)\n",
    "        ability_emb = self.ability_embedding(ability)\n",
    "        types_emb   = self.types_embedding(types)\n",
    "        moves_emb   = self.moves_embedding(moves).flatten()\n",
    "        hp_tensor   = poke_vec_tensor[2].unsqueeze(0)  # pour concat\n",
    "\n",
    "        out = torch.cat([species_emb, item_emb, hp_tensor, ability_emb, types_emb, mid_vec, moves_emb], dim=0)\n",
    "        return out\n",
    "    \n",
    "    ####Renvoies le vecteur embedding pour tout le vecteur obs####\n",
    "    def embedding_obs(self, obs) :\n",
    "        my_active_poke = obs[12+12+2:12+12+2+23]\n",
    "        my_other_pokes = [obs[49+16*i:49+16*(i+1)] for i in range(5)]\n",
    "        my_opponent_active_poke = obs[129:129+23]\n",
    "        my_opponent_other_pokes = [obs[152+16*i:152+16*(i+1)] for i in range(5)]\n",
    "        #J'ai récupéré ce que je voulais dans le numpy, maintenant je passe en tensor\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32)\n",
    "        obs_conditions_and_weather = obs_tensor[:26]\n",
    "        obs_action_size = obs_tensor[232].unsqueeze(0)\n",
    "        #Embeddings\n",
    "        active_poke_emb = self.embed_pokemon(my_active_poke,is_active_poke = 1)\n",
    "        my_other_pokes_emb = torch.cat([self.embed_pokemon(my_other_pokes[i],is_active_poke=0) for i in range(5)], dim=0) \n",
    "        my_opponent_active_poke_emb = self.embed_pokemon(my_opponent_active_poke,is_active_poke = 1)\n",
    "        my_opponent_other_pokes_emb = torch.cat([self.embed_pokemon(my_opponent_other_pokes[i],is_active_poke=0) for i in range(5)], dim=0)\n",
    "\n",
    "        out = torch.cat([obs_conditions_and_weather,active_poke_emb,my_other_pokes_emb,my_opponent_active_poke_emb,my_opponent_other_pokes_emb,obs_action_size])\n",
    "\n",
    "        return out # TAILLE 1565\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Donc x doit être obs de ce que j'ai compris, pas S\n",
    "        x = self.embedding_obs(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poke_env.player.random_player import RandomPlayer\n",
    "\n",
    "class MyEnvPlayer(Gen4EnvSinglePlayer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "         super().__init__(*args, **kwargs)\n",
    "     \n",
    "    def embed_battle(self, battle) -> np.ndarray: #renvoie obs\n",
    "        #if battle.turn == 1 : \n",
    "        obs = adapted_obs(battle) \n",
    "        obs = obs.output\n",
    "        #else : \n",
    "            #obs = obs.update(battle)\n",
    "            \n",
    "        return obs\n",
    "\n",
    "    def calc_reward(self, current_battle,last_battle) -> float:\n",
    "        # Reward simple : +1 si l'adversaire est KO, -1 si toi tu l'es\n",
    "        reward = 0\n",
    "        if last_battle.opponent_active_pokemon and current_battle.opponent_active_pokemon.fainted:\n",
    "            reward += 1\n",
    "        if last_battle.active_pokemon and current_battle.active_pokemon.fainted:\n",
    "            reward -= 1\n",
    "        return reward\n",
    "\n",
    "    def describe_embedding(self) -> tuple:\n",
    "        return (2,), np.float32  # 2 valeurs float (my HP, opp HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = RandomPlayer(battle_format=\"gen4randombattle\")\n",
    "\n",
    "# Ton agent (env Gym-compatible)\n",
    "env = MyEnvPlayer(battle_format=\"gen4randombattle\", opponent=opponent)\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.72699386 0.06818182 1.         0.64705884\n",
      " 0.58441556 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.49801588 0.2936508  0.28373015\n",
      " 0.40873015 0.2857143  0.42857143 0.02139037 0.21390374 1.\n",
      " 0.7058824  0.83128834 0.13636364 1.         0.8627451  0.11688311\n",
      " 0.         0.5952381  0.31547618 0.46825397 0.29960316 0.53571427\n",
      " 0.31547618 0.6042781  0.8983957  0.973262   0.5828877  0.47239265\n",
      " 0.13636364 1.         0.85294116 0.9935065  0.         0.4920635\n",
      " 0.12896825 0.3313492  0.2718254  0.37103173 0.49801588 0.8983957\n",
      " 0.8395722  0.4331551  0.6042781  0.49386504 0.13636364 1.\n",
      " 0.29411766 0.9935065  0.         0.5436508  0.30753967 0.38492063\n",
      " 0.38492063 0.38492063 0.38492063 0.8395722  0.22994652 0.86096257\n",
      " 0.4331551  0.86503065 0.13636364 1.         0.         0.00649351\n",
      " 0.         0.5734127  0.29563493 0.32738096 0.29563493 0.4047619\n",
      " 0.44444445 0.86096257 0.6898396  0.04812834 0.09090909 0.12883435\n",
      " 0.77272725 1.         0.         0.43506494 0.         0.45039684\n",
      " 0.50396824 0.3452381  0.28174603 0.28174603 0.31349206 0.29946524\n",
      " 0.8128342  0.7914438  0.80213904 0.81595093 0.         1.\n",
      " 0.5        0.71428573 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6984127  0.5456349\n",
      " 0.5297619  0.4107143  0.45039684 0.33531746 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6666667 ]\n"
     ]
    }
   ],
   "source": [
    "############ CODE POUR DEROULER TOUT UN MATCH ###########\n",
    "\n",
    "# Adversaire\n",
    "opponent = RandomPlayer(battle_format=\"gen4randombattle\")\n",
    "\n",
    "# Ton agent (env Gym-compatible)\n",
    "env = MyEnvPlayer(battle_format=\"gen4randombattle\", opponent=opponent)\n",
    "\n",
    "# Lancer un match\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "1565\n"
     ]
    }
   ],
   "source": [
    "model = NNModel(1565,9)\n",
    "print(len(obs))\n",
    "obs_tensor = model.embedding_obs(obs)\n",
    "print(len(obs_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  ...,  1.1430, -0.2957,  0.6667],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(obs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species max: 326\n",
      "item max: 44\n",
      "ability max: 102\n",
      "types max: 154\n",
      "moves max: 187\n"
     ]
    }
   ],
   "source": [
    "print(\"species max:\", len(species_to_id))\n",
    "print(\"item max:\", len(item_to_id))\n",
    "print(\"ability max:\", len(ability_to_id))\n",
    "print(\"types max:\", len(types_to_id))\n",
    "print(\"moves max:\", len(moves_to_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent : \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## DEFINIR L'EMBEDDING ##################\n",
    "import time\n",
    "import random\n",
    "# Initialiser GenData pour la génération souhaitée (par exemple, génération 4)\n",
    "gen_data = GenData.from_gen(4)\n",
    "\n",
    "# Accéder au tableau des types\n",
    "type_chart = gen_data.type_chart\n",
    "\n",
    "\n",
    "from poke_env.player.env_player import Gen4EnvSinglePlayer\n",
    "import numpy as np\n",
    "import time, random\n",
    "\n",
    "class Player5Training(Gen4EnvSinglePlayer):\n",
    "    def __init__(self, model, battle_format=\"gen4randombattle\",max_concurrent_battles=1, **kwargs):\n",
    "        self._max_concurrent_battles = max_concurrent_battles\n",
    "        super().__init__(battle_format=battle_format,**kwargs)\n",
    "        self._init_environment()\n",
    "        self.model = model\n",
    "        self.action_space = Discrete(9)\n",
    "\n",
    "    def _init_environment(self):\n",
    "            # Hack pour forcer poke-env à prendre en compte le bon nombre de battles\n",
    "            self._n_battles = self._max_concurrent_battles\n",
    "\n",
    "    def embed_battle(self, battle):\n",
    "        # Remplace ça par ta propre obs\n",
    "        obs = adapted_obs(battle).output\n",
    "        return obs\n",
    "\n",
    "    def describe_embedding(self):\n",
    "        return Box(low=0, high=256, shape=(233,), dtype=np.float32)\n",
    "\n",
    "    def calc_reward(self, last_battle, current_battle):\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def action_to_move(self, action, battle):\n",
    "        return super().action_to_move(action, battle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptation à SB3/Gym et tout le bordel :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle modifié pour que ça marche avec des batchs (c'est un bordel) :\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NNModel2(nn.Module):\n",
    "    def __init__(self, input_dim, n_actions):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "        # Réseau principal\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, n_actions)\n",
    "\n",
    "        # Embeddings\n",
    "        self.item_embedding = nn.Embedding(len(item_to_id) + 1, 8)\n",
    "        self.ability_embedding = nn.Embedding(len(ability_to_id) + 1, 8)\n",
    "        self.moves_embedding = nn.Embedding(len(moves_to_id) + 1, 16)\n",
    "        self.species_embedding = nn.Embedding(len(species_to_id) + 1, 32)\n",
    "        self.types_embedding = nn.Embedding(len(types_to_id) + 1, 8)\n",
    "\n",
    "        self.move_to_device()  # safe move for MPS\n",
    "\n",
    "    def move_to_device(self):\n",
    "        self.to(self.device)\n",
    "        for emb in [\n",
    "            self.item_embedding,\n",
    "            self.ability_embedding,\n",
    "            self.moves_embedding,\n",
    "            self.species_embedding,\n",
    "            self.types_embedding\n",
    "        ]:\n",
    "            emb.weight.data = emb.weight.data.to(self.device)\n",
    "\n",
    "    def embed_pokemon(self, poke_vec, is_active_poke):\n",
    "        device = self.device\n",
    "        species  = torch.tensor(int(poke_vec[0]), dtype=torch.long, device=device)\n",
    "        item     = torch.tensor(int(poke_vec[1]), dtype=torch.long, device=device)\n",
    "        ability  = torch.tensor(int(poke_vec[3]), dtype=torch.long, device=device)\n",
    "        types    = torch.tensor(int(poke_vec[4]), dtype=torch.long, device=device)\n",
    "        poke_vec_tensor = torch.as_tensor(poke_vec, dtype=torch.float32, device=device)\n",
    "\n",
    "        if is_active_poke == 0:\n",
    "            moves = torch.as_tensor(poke_vec[11:15], dtype=torch.long, device=device)\n",
    "            mid_vec = poke_vec_tensor[5:11]\n",
    "        else:\n",
    "            moves = torch.as_tensor(poke_vec[18:22], dtype=torch.long, device=device)\n",
    "            mid_vec = poke_vec_tensor[5:18]\n",
    "\n",
    "        species_emb = self.species_embedding(species)\n",
    "        item_emb    = self.item_embedding(item)\n",
    "        ability_emb = self.ability_embedding(ability)\n",
    "        types_emb   = self.types_embedding(types)\n",
    "        moves_emb   = self.moves_embedding(moves).flatten()\n",
    "        hp_tensor   = poke_vec_tensor[2].unsqueeze(0)\n",
    "\n",
    "        out = torch.cat([species_emb, item_emb, hp_tensor, ability_emb, types_emb, mid_vec, moves_emb], dim=0)\n",
    "        return out\n",
    "\n",
    "    def embedding_obs(self, obs_batch):\n",
    "        batch_size = obs_batch.shape[0]\n",
    "        obs_conditions_and_weather = obs_batch[:, :26]\n",
    "        obs_action_size = obs_batch[:, IDX_ACTION_SPACE_SIZE].unsqueeze(1)\n",
    "\n",
    "        my_active_pokes = obs_batch[:, 26+12+2 : 26+12+2+23]\n",
    "        my_other_pokes = [obs_batch[:, 49+16*i : 49+16*(i+1)] for i in range(5)]\n",
    "        my_opponent_active_pokes = obs_batch[:, 129:129+23]\n",
    "        my_opponent_other_pokes = [obs_batch[:, 152+16*i : 152+16*(i+1)] for i in range(5)]\n",
    "\n",
    "        active_poke_emb = torch.stack([self.embed_pokemon(my_active_pokes[i], is_active_poke=1) for i in range(batch_size)])\n",
    "\n",
    "        other_pokes_emb = torch.cat([\n",
    "            torch.stack([self.embed_pokemon(my_other_pokes[j][i], is_active_poke=0) for i in range(batch_size)])\n",
    "            for j in range(5)\n",
    "        ], dim=1)\n",
    "\n",
    "        opponent_active_emb = torch.stack([self.embed_pokemon(my_opponent_active_pokes[i], is_active_poke=1) for i in range(batch_size)])\n",
    "\n",
    "        opponent_other_emb = torch.cat([\n",
    "            torch.stack([self.embed_pokemon(my_opponent_other_pokes[j][i], is_active_poke=0) for i in range(batch_size)])\n",
    "            for j in range(5)\n",
    "        ], dim=1)\n",
    "\n",
    "        return torch.cat([obs_conditions_and_weather, active_poke_emb, other_pokes_emb,\n",
    "                          opponent_active_emb, opponent_other_emb, obs_action_size], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == 1565, f\"Taille incorrecte: attendu 1565, reçu {x.shape[1]}\"\n",
    "        self.to(self.device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que c'est bon : \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On change : pas d'embedding, on passe obs directement \n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class CustomExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=1565):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        self.nnmodel = NNModel2(input_dim=1565, n_actions=9)\n",
    "        self.nnmodel.move_to_device()  # force device correction\n",
    "\n",
    "        self._features_dim = features_dim\n",
    "\n",
    "    def forward(self, observations):\n",
    "        # Sécurité anti-clone : on force le modèle à rester sur le bon device\n",
    "        self.nnmodel.move_to_device()\n",
    "\n",
    "        obs = observations.to(self.nnmodel.device)\n",
    "        x = obs # A la base : self.nnmodel.embedding_obs(obs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "class CustomPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            features_extractor_class=CustomExtractor,\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir l'adversaire (on prend random)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train\n",
    "-\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : le vecteur S de taille 1565 est passé à un vecteur de taille 128 avec un nouvel embedding. C'est curieux, pour l'instant on laisse parce que\n",
    "ça laissera au moins l'entrainement être plus rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "#from stable_baselines3 import PPO\n",
    "#from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "#N_ENVS = 2\n",
    "\n",
    "#my_model = NNModel2(input_dim=233,n_actions=9)\n",
    "\n",
    "#def make_env(i):\n",
    "#    opponent = MyRandomPlayer(i=1+i)  # nom différent pour chaque adversaire\n",
    "#    return Player5Training(i=i, model=my_model, battle_format=\"gen4randombattle\", opponent=opponent)\n",
    "\n",
    "#train_envs = SubprocVecEnv([lambda i=i: make_env(i) for i in range(N_ENVS)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "#my_model = NNModel2(233,9)\n",
    "#train_env_raw = Player5Training(\n",
    "#    model=my_model,\n",
    "#    opponent=RandomPlayer(battle_format=\"gen4randombattle\"),\n",
    "#    start_challenging=True\n",
    "#)\n",
    "\n",
    "#train_env = DummyVecEnv([lambda: train_env_raw])  # Redéfini bien après reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines3 import PPO\n",
    "#device=\"cpu\"\n",
    "\n",
    "#model = PPO(policy=CustomPolicy, batch_size=4, env=train_env, device=device,n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.learn(total_timesteps=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie DQN avec ce nouvel obs et embedding pour voir un truc : \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.dqn.policies import DQNPolicy\n",
    "from stable_baselines3.common.torch_layers import create_mlp\n",
    "from torch import optim\n",
    "\n",
    "class CustomDQNPolicy(DQNPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        # Forcer les bons paramètres dans kwargs\n",
    "        kwargs[\"features_extractor_class\"] = CustomExtractor\n",
    "        kwargs[\"features_extractor_kwargs\"] = {\"features_dim\": 1565}\n",
    "        kwargs[\"net_arch\"] = [512, 256, 128]  # ou [] si tout est géré dans CustomExtractor\n",
    "\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            **kwargs\n",
    "        )\n",
    "        self._build(lr_schedule)\n",
    "        self.q_net.to(self.device)\n",
    "        self.q_net_target.to(self.device)\n",
    "\n",
    "class CustomDQNPolicySGD(DQNPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        kwargs[\"net_arch\"] = [512,256,128,64,64,32]\n",
    "        super().__init__(observation_space, action_space, lr_schedule, **kwargs)\n",
    "    def make_optimizers(self) -> None:\n",
    "        # Redéfinir l'optimiseur ici\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.lr_schedule(1),  # learning_rate peut être une fonction\n",
    "            momentum=0.9,            # optionnel\n",
    "            weight_decay=0.0         # optionnel\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.embedding.old.old_embedding import *\n",
    "from Utils.embedding.old.type_autoencodeur import TypeAutoencoder\n",
    "import Players.Player4 as player4\n",
    "\n",
    "encodeur_type = TypeAutoencoder(encoded_size=4)\n",
    "\n",
    "# Charger les poids sauvegardés\n",
    "encodeur_type.load_state_dict(torch.load(\"Utils/embedding/old/type_autoencoder.pth\", map_location='cpu'))\n",
    "encodeur_type.eval()\n",
    "\n",
    "class AdversarialTrainPlayer(RandomPlayer): # Adversaire de Player4 lors de l'entrainement\n",
    "\n",
    "    def __init__(self, model_path=\"Players/player_4\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        self.model = DQN.load(model_path, device=device)\n",
    "        print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "\n",
    "    def embed_battle(self, battle)  :\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        moves_real_power = -np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "                moves_real_power[i] = moves_dmg_multiplier[i]*moves_base_power[i]\n",
    "\n",
    "        if battle.turn == 1:\n",
    "            self.my_team, self.my_team_index = player4.init_my_team(battle)\n",
    "            self.opponent_team, self.opponent_team_index = player4.init_opponent_team(battle)\n",
    "        else : \n",
    "            self.my_team = player4.update_my_team(battle, self.my_team, self.my_team_index)\n",
    "            self.opponent_team, self.opponent_team_index = player4.update_opponent_team(battle, self.opponent_team, self.opponent_team_index)\n",
    "\n",
    "        \n",
    "\n",
    "        # Final vector with 10 components\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_real_power,\n",
    "                self.my_team,\n",
    "                self.opponent_team\n",
    "            ]\n",
    "        )\n",
    "        return final_vector\n",
    "    \n",
    "    #action_to_move suppr\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = (\n",
    "            [-1] * 4 +          # real power\n",
    "            [0] * 72 +         # my team types\n",
    "            [0] * 72           # opponent team types\n",
    "        )\n",
    "        high = (\n",
    "            [3] * 4 +           # real power\n",
    "            [1] * 72 +         # my team types\n",
    "            [1] * 72           # opponent team types\n",
    "        )\n",
    "\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "    def predict(self, obs):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "        q_values = self.model.q_net(obs_tensor)\n",
    "        print(f\"📊 Q-values : {q_values.detach().numpy().flatten()}\")\n",
    "        action = int(torch.argmax(q_values).item())\n",
    "        return action\n",
    "    \n",
    "    def choose_move(self, battle):\n",
    "        obs = self.embed_battle(battle)\n",
    "        device  = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(obs_tensor)\n",
    "            action = int(torch.argmax(q_values).item())\n",
    "\n",
    "        moves = battle.available_moves\n",
    "        switches = battle.available_switches\n",
    "        total_actions = len(moves) + len(switches)\n",
    "\n",
    "        if 0 <= action < len(moves):\n",
    "            return self.create_order(moves[action])\n",
    "        elif len(moves) <= action < total_actions:\n",
    "            return self.create_order(switches[action - len(moves)])\n",
    "        else:\n",
    "            return self.choose_random_move(battle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle chargé depuis Players/player_4\n"
     ]
    }
   ],
   "source": [
    "#opponent = AdversarialTrainPlayer(battle_format=\"gen4randombattle\")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Réinstancier l'env\n",
    "opponent = AdversarialTrainPlayer(battle_format=\"gen4randombattle\")\n",
    "\n",
    "train_env_raw = Player5Training(\n",
    "    model = None,\n",
    "    battle_format=\"gen4randombattle\",\n",
    "    opponent=opponent,\n",
    "    max_concurrent_battles=10\n",
    ")\n",
    "\n",
    "train_env = DummyVecEnv([lambda: train_env_raw])  # Redéfini bien après reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "#déclarer nouveau modèle vierge\n",
    "#On essaie PPO\n",
    "from stable_baselines3 import DQN\n",
    "#env = train_env\n",
    "\n",
    "model = DQN(\n",
    "    policy=CustomDQNPolicySGD, #A la base : CustomDQNPolicy\n",
    "    env=train_env,\n",
    "    learning_rate=2.5e-4,\n",
    "    buffer_size=10000,\n",
    "    learning_starts=1000,\n",
    "    batch_size=32,\n",
    "    gamma=0.5,\n",
    "    train_freq=8,\n",
    "    target_update_interval=1,\n",
    "    exploration_fraction=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    verbose=1,\n",
    "    device=\"mps\",\n",
    "    _init_setup_model=True #intialement à False quand on prenait des envs custom\n",
    ")\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#model = DQN.load('Players/player5_nn2', device=device)\n",
    "#model._setup_model()\n",
    "\n",
    "#model.q_net.to(\"mps\")\n",
    "#model.q_net_target.to(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload le modèle\n",
    "#device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#model = DQN.load(\"Players/player5_nn2\", env=train_env, device=device, custom_objects={\"policy_class\": CustomDQNPolicy})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1m36 à 10 concurrent_battles\n",
    "1m39 à 20 \n",
    "1m29/1m49 à 5 : ça change pas grand chose\n",
    "\n",
    "On va garder 10 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:06:27,408 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Regirock', 'Earthquake', 'p2a: Houndoom', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200429 turn 11\n",
      "2025-06-17 14:06:27,415 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Regirock', 'Earthquake', 'p2a: Bibarel', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200429 turn 12\n",
      "2025-06-17 14:06:29,531 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Shuckle', '[from] lockedmove'] in battle battle-gen4randombattle-200437 turn 2\n",
      "2025-06-17 14:06:29,538 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Shuckle', '[from] lockedmove'] in battle battle-gen4randombattle-200437 turn 3\n",
      "2025-06-17 14:06:33,744 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Kingdra', 'Outrage', 'p1a: Ariados', '[from] lockedmove'] in battle battle-gen4randombattle-200453 turn 24\n",
      "2025-06-17 14:06:35,801 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Altaria', 'Outrage', 'p2a: Cacturne', '[from] lockedmove'] in battle battle-gen4randombattle-200462 turn 7\n",
      "2025-06-17 14:06:36,744 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Giratina', 'Outrage', 'p2a: Sceptile', '[from] lockedmove'] in battle battle-gen4randombattle-200466 turn 14\n",
      "2025-06-17 14:06:37,081 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Rayquaza', 'Outrage', 'p1a: Mamoswine', '[from] lockedmove'] in battle battle-gen4randombattle-200467 turn 9\n",
      "2025-06-17 14:06:43,612 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Pelipper', '[from] lockedmove'] in battle battle-gen4randombattle-200490 turn 12\n",
      "2025-06-17 14:06:49,287 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Arceus', 'Outrage', 'p1a: Beautifly', '[from] lockedmove'] in battle battle-gen4randombattle-200508 turn 16\n",
      "2025-06-17 14:06:49,305 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Arceus', 'Outrage', 'p1a: Azelf', '[from] lockedmove'] in battle battle-gen4randombattle-200508 turn 18\n",
      "2025-06-17 14:06:49,334 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Arceus', 'Outrage', 'p1a: Manaphy', '[from] lockedmove'] in battle battle-gen4randombattle-200508 turn 20\n",
      "2025-06-17 14:06:49,376 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Arceus', 'Outrage', 'p1a: Dunsparce', '[from] lockedmove'] in battle battle-gen4randombattle-200508 turn 22\n",
      "2025-06-17 14:06:50,514 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Victreebel', 'Solar Beam', 'p1a: Grumpig', '[from] lockedmove'] in battle battle-gen4randombattle-200512 turn 22\n",
      "2025-06-17 14:06:52,322 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Kyogre', 'Surf', 'p2a: Lugia', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200518 turn 29\n",
      "2025-06-17 14:06:53,730 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Flygon', 'Outrage', 'p2a: Bellossom', '[from] lockedmove'] in battle battle-gen4randombattle-200522 turn 16\n",
      "2025-06-17 14:06:53,741 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Flygon', 'Outrage', 'p2a: Bellossom', '[from] lockedmove'] in battle battle-gen4randombattle-200522 turn 17\n",
      "2025-06-17 14:06:53,924 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Entei', '[from] lockedmove'] in battle battle-gen4randombattle-200523 turn 8\n",
      "2025-06-17 14:06:53,934 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Entei', '[from] lockedmove'] in battle battle-gen4randombattle-200523 turn 9\n",
      "2025-06-17 14:06:56,119 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Walrein', '[from] lockedmove'] in battle battle-gen4randombattle-200529 turn 25\n",
      "2025-06-17 14:06:56,996 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Absol', 'Pursuit', 'p1a: Blastoise', '[from] Pursuit'] in battle battle-gen4randombattle-200532 turn 1\n",
      "2025-06-17 14:06:57,083 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Flygon', 'Outrage', 'p1a: Clefable', '[from] lockedmove'] in battle battle-gen4randombattle-200532 turn 7\n",
      "2025-06-17 14:07:01,731 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Dialga', 'Outrage', 'p2a: Mewtwo', '[from] lockedmove'] in battle battle-gen4randombattle-200542 turn 11\n",
      "2025-06-17 14:07:02,696 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Weezing', 'Fire Blast', 'p2a: Ariados', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200545 turn 28\n",
      "2025-06-17 14:07:05,516 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Garchomp', 'Outrage', 'p2a: Linoone', '[from] lockedmove'] in battle battle-gen4randombattle-200552 turn 13\n",
      "2025-06-17 14:07:05,529 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Garchomp', 'Outrage', 'p2a: Linoone', '[from] lockedmove'] in battle battle-gen4randombattle-200552 turn 14\n",
      "2025-06-17 14:07:05,670 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Typhlosion', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 2\n",
      "2025-06-17 14:07:05,676 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Muk', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 3\n",
      "2025-06-17 14:07:05,693 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Beautifly', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 4\n",
      "2025-06-17 14:07:05,710 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Donphan', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 6\n",
      "2025-06-17 14:07:05,736 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Typhlosion', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 9\n",
      "2025-06-17 14:07:05,742 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Muk', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 10\n",
      "2025-06-17 14:07:05,772 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Poliwrath', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 13\n",
      "2025-06-17 14:07:05,786 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Spiritomb', 'Pursuit', 'p1a: Muk', '[from] Pursuit'] in battle battle-gen4randombattle-200553 turn 15\n",
      "2025-06-17 14:07:06,284 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Giratina', 'Outrage', 'p1a: Tyranitar', '[from] lockedmove'] in battle battle-gen4randombattle-200554 turn 29\n",
      "2025-06-17 14:07:07,934 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Toxic', 'p2a: Floatzel', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 28\n",
      "2025-06-17 14:07:08,128 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Toxic', 'p2a: Dustox', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 52\n",
      "2025-06-17 14:07:08,228 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Waterfall', 'p2a: Dustox', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 63\n",
      "2025-06-17 14:07:08,307 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Rest', '', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 73\n",
      "2025-06-17 14:07:08,316 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Waterfall', 'p2a: Vaporeon', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 74\n",
      "2025-06-17 14:07:08,376 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Waterfall', 'p2a: Vaporeon', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200559 turn 81\n",
      "2025-06-17 14:07:09,291 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Kingdra', 'Outrage', 'p2a: Tyranitar', '[from] lockedmove'] in battle battle-gen4randombattle-200562 turn 17\n",
      "2025-06-17 14:07:11,552 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Altaria', 'Outrage', 'p2a: Ledian', '[from] lockedmove'] in battle battle-gen4randombattle-200569 turn 36\n",
      "2025-06-17 14:07:13,108 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Victreebel', 'Solar Beam', 'p1a: Hitmonlee', '[from] lockedmove'] in battle battle-gen4randombattle-200574 turn 27\n",
      "2025-06-17 14:07:13,777 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Dragonite', 'Outrage', 'p2a: Furret', '[from] lockedmove'] in battle battle-gen4randombattle-200577 turn 7\n",
      "2025-06-17 14:07:16,027 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Milotic', 'Rest', '', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200581 turn 45\n",
      "2025-06-17 14:07:16,066 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Milotic', 'Toxic', 'p2a: Tauros', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200581 turn 49\n",
      "2025-06-17 14:07:17,826 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Wormadam', 'Toxic', '', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200588 turn 19\n",
      "2025-06-17 14:07:17,833 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Wormadam', 'Rest', '', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200588 turn 20\n",
      "2025-06-17 14:07:17,905 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Kricketune', '[from] lockedmove'] in battle battle-gen4randombattle-200589 turn 2\n",
      "2025-06-17 14:07:17,913 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Kricketune', '[from] lockedmove'] in battle battle-gen4randombattle-200589 turn 3\n",
      "2025-06-17 14:07:17,937 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Blastoise', '[from] lockedmove'] in battle battle-gen4randombattle-200589 turn 5\n",
      "2025-06-17 14:07:17,952 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Zangoose', '[from] lockedmove'] in battle battle-gen4randombattle-200589 turn 6\n",
      "2025-06-17 14:07:18,888 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Rayquaza', 'Outrage', 'p2a: Vespiquen', '[from] lockedmove'] in battle battle-gen4randombattle-200591 turn 28\n",
      "2025-06-17 14:07:20,475 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Dustox', '[from] lockedmove'] in battle battle-gen4randombattle-200595 turn 13\n",
      "2025-06-17 14:07:20,496 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Dustox', '[from] lockedmove'] in battle battle-gen4randombattle-200595 turn 15\n",
      "2025-06-17 14:07:20,518 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Dustox', '[from] lockedmove'] in battle battle-gen4randombattle-200595 turn 16\n",
      "2025-06-17 14:07:20,545 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Dustox', '[from] lockedmove'] in battle battle-gen4randombattle-200595 turn 18\n",
      "2025-06-17 14:07:20,575 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Dustox', '[from] lockedmove'] in battle battle-gen4randombattle-200595 turn 21\n",
      "2025-06-17 14:07:22,706 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Kingdra', 'Outrage', 'p1a: Swampert', '[from] lockedmove'] in battle battle-gen4randombattle-200601 turn 5\n",
      "2025-06-17 14:07:23,566 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Salamence', 'Outrage', 'p2a: Probopass', '[from] lockedmove'] in battle battle-gen4randombattle-200603 turn 23\n",
      "2025-06-17 14:07:23,667 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Registeel', 'Iron Head', 'p2a: Regice', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200604 turn 5\n",
      "2025-06-17 14:07:33,107 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Bronzong', '[from] lockedmove'] in battle battle-gen4randombattle-200627 turn 50\n",
      "2025-06-17 14:07:33,137 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Bronzong', '[from] lockedmove'] in battle battle-gen4randombattle-200627 turn 52\n",
      "2025-06-17 14:07:36,026 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Poliwrath', 'Waterfall', 'p2a: Dragonite', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200636 turn 29\n",
      "2025-06-17 14:07:36,027 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Poliwrath', '[from] lockedmove'] in battle battle-gen4randombattle-200636 turn 29\n",
      "2025-06-17 14:07:37,892 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Tyranitar', '[from] lockedmove'] in battle battle-gen4randombattle-200642 turn 4\n",
      "2025-06-17 14:07:37,902 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Ledian', '[from] lockedmove'] in battle battle-gen4randombattle-200642 turn 5\n",
      "2025-06-17 14:07:37,946 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Tyranitar', '[from] lockedmove'] in battle battle-gen4randombattle-200642 turn 8\n",
      "2025-06-17 14:07:46,809 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Giratina', 'Calm Mind', 'p1a: Giratina', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200664 turn 30\n",
      "2025-06-17 14:07:46,908 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Flygon', 'Outrage', 'p2a: Sandslash', '[from] lockedmove'] in battle battle-gen4randombattle-200665 turn 8\n",
      "2025-06-17 14:07:54,373 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Registeel', 'Toxic', 'p2a: Kecleon', '[from] move: Sleep Talk'] in battle battle-gen4randombattle-200685 turn 80\n",
      "2025-06-17 14:07:57,594 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Kingdra', 'Outrage', 'p1: Deoxys', '[from] lockedmove'] in battle battle-gen4randombattle-200693 turn 3\n",
      "2025-06-17 14:07:57,695 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Dialga', 'Outrage', 'p2a: Weezing', '[from] lockedmove'] in battle battle-gen4randombattle-200693 turn 11\n",
      "2025-06-17 14:07:58,486 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Victreebel', 'Solar Beam', 'p1a: Chimecho', '[from] lockedmove'] in battle battle-gen4randombattle-200696 turn 3\n",
      "2025-06-17 14:07:59,373 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Victreebel', 'Solar Beam', 'p2a: Kangaskhan', '[from] lockedmove'] in battle battle-gen4randombattle-200698 turn 20\n",
      "2025-06-17 14:07:59,558 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Garchomp', 'Outrage', 'p1a: Girafarig', '[from] lockedmove'] in battle battle-gen4randombattle-200699 turn 12\n",
      "2025-06-17 14:07:59,575 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Garchomp', 'Outrage', 'p1a: Sudowoodo', '[from] lockedmove'] in battle battle-gen4randombattle-200699 turn 13\n",
      "2025-06-17 14:08:00,959 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Kingdra', 'Outrage', 'p1a: Mew', '[from] lockedmove'] in battle battle-gen4randombattle-200701 turn 17\n",
      "2025-06-17 14:08:02,800 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Ampharos', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 8\n",
      "2025-06-17 14:08:02,839 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Hypno', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 10\n",
      "2025-06-17 14:08:02,864 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Vaporeon', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 12\n",
      "2025-06-17 14:08:02,877 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Vaporeon', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 13\n",
      "2025-06-17 14:08:02,937 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Hitmonchan', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 17\n",
      "2025-06-17 14:08:02,947 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dialga', 'Outrage', 'p1a: Hitmonchan', '[from] lockedmove'] in battle battle-gen4randombattle-200707 turn 18\n",
      "2025-06-17 14:08:06,851 - AdversarialTrain 1 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Garchomp', 'Outrage', 'p2a: Empoleon', '[from] lockedmove'] in battle battle-gen4randombattle-200718 turn 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 136      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 139      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 133      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 283      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 433      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 556      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 696      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 135      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 836      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 134      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 957      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 129      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 1055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.35     |\n",
      "|    n_updates        | 6        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 127      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 1164     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.381    |\n",
      "|    n_updates        | 20       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 1287     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.36     |\n",
      "|    n_updates        | 35       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 126      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 1406     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 50       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 1547     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 68       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 124      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 1679     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.697    |\n",
      "|    n_updates        | 84       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 122      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 1776     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 96       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 121      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 1931     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 116      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 119      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2022     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.509    |\n",
      "|    n_updates        | 127      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 117      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 2139     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 142      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 116      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 2285     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 160      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 2402     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 175      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 115      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 2553     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.514    |\n",
      "|    n_updates        | 194      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 114      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 2667     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 208      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 113      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 2779     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 222      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 112      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 2914     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.333    |\n",
      "|    n_updates        | 239      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 112      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 3034     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.537    |\n",
      "|    n_updates        | 254      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 111      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 3187     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.35     |\n",
      "|    n_updates        | 273      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 110      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 3325     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.44     |\n",
      "|    n_updates        | 290      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 110      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 3464     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 307      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 110      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 3675     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.35     |\n",
      "|    n_updates        | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 109      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 3828     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 353      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 3962     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.56     |\n",
      "|    n_updates        | 370      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 4151     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 393      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 4299     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 412      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 4496     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 436      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 107      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 4603     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.557    |\n",
      "|    n_updates        | 450      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 107      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 4720     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 464      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 107      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 4845     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 480      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 4961     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 495      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 5112     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 513      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 106      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 5252     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 531      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 5364     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.507    |\n",
      "|    n_updates        | 545      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 5516     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.38     |\n",
      "|    n_updates        | 564      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 105      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 5651     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.36     |\n",
      "|    n_updates        | 581      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 5812     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 601      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 5920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.386    |\n",
      "|    n_updates        | 614      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 6055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 631      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 104      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 6174     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 646      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 6338     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 667      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 6482     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 685      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 6619     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.66     |\n",
      "|    n_updates        | 702      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 6843     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.311    |\n",
      "|    n_updates        | 730      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 6958     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.533    |\n",
      "|    n_updates        | 744      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 103      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 7074     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.51     |\n",
      "|    n_updates        | 759      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 7188     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 773      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 7337     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 792      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 7457     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 807      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 7624     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 827      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.262    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 102      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 7772     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.458    |\n",
      "|    n_updates        | 846      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 7930     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 866      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.235    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 8055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.62     |\n",
      "|    n_updates        | 881      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 8207     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 900      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.204    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 8382     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 922      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 8487     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.493    |\n",
      "|    n_updates        | 935      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 8576     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.6      |\n",
      "|    n_updates        | 946      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 8688     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 960      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 8882     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 985      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 9084     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.503    |\n",
      "|    n_updates        | 1010     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.127    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 9192     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.421    |\n",
      "|    n_updates        | 1023     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 9327     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.41     |\n",
      "|    n_updates        | 1040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0974   |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 9501     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.48     |\n",
      "|    n_updates        | 1062     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0864   |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 9617     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 1077     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0715   |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 9774     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.06     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 100      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 9895     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.49     |\n",
      "|    n_updates        | 1111     |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_env.reset()\n",
    "#for i in range(100):\n",
    "#    print(f\"🎯 Training block {i+1}\")\n",
    "#    model.learn(total_timesteps=1000)\n",
    "#    model.save(\"Players/player5_nn2\")\n",
    "\n",
    "model.learn(total_timesteps=10_000)\n",
    "model.save(\"Players/player5_nn3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de l'observation : (1, 233)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09509202 0.1590909  1.         0.38235295\n",
      "  0.9350649  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.48015872 0.39087301 0.3015873\n",
      "  0.4702381  0.3015873  0.44047618 0.6096257  0.5508021  0.87700534\n",
      "  0.2620321  0.35276073 0.77272725 1.         0.         0.4090909\n",
      "  0.         0.7619048  0.5019841  0.29960316 0.23214285 0.29960316\n",
      "  0.26587301 0.2513369  0.11764706 0.5828877  0.80213904 0.6595092\n",
      "  0.13636364 1.         0.71568626 0.8636364  0.         0.625\n",
      "  0.61507934 0.45238096 0.3531746  0.45238096 0.4186508  0.8128342\n",
      "  0.6631016  0.8930481  0.21925133 0.13496932 0.13636364 1.\n",
      "  0.12745099 0.04545455 0.         0.5297619  0.27579364 0.29563493\n",
      "  0.40873015 0.40873015 0.37103173 0.09090909 0.80748665 0.7540107\n",
      "  0.93048126 0.22699386 0.02272727 1.         0.32352942 0.24675325\n",
      "  0.         0.5138889  0.4861111  0.3690476  0.38492063 0.38492063\n",
      "  0.32539684 0.21925133 0.56684494 0.8342246  0.24598931 0.19325154\n",
      "  0.13636364 1.         0.         0.8636364  0.         0.5992063\n",
      "  0.37103173 0.37103173 0.3313492  0.3313492  0.39087301 0.6042781\n",
      "  0.973262   0.171123   0.8983957  0.66564417 0.         1.\n",
      "  0.09803922 0.9805195  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.6388889  0.4107143\n",
      "  0.7083333  0.4107143  0.7083333  0.31150794 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "obs = train_env.reset()\n",
    "print(\"Shape de l'observation :\", obs.shape)\n",
    "print(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player5Test(Gen4EnvSinglePlayer):\n",
    "    def __init__(self, model_path=\"Players/player5_nn3\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        self.model = DQN.load(model_path, device=device )\n",
    "        print(f\"📥 Modèle chargé depuis {model_path}\")\n",
    "\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            current_battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle):\n",
    "        obs = adapted_obs(battle)\n",
    "        return obs.output\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        return Box(low=np.zeros(233), high=np.full(233, 256), dtype=np.float32)\n",
    "\n",
    "    def action_to_move(self, action: int, battle: AbstractBattle):\n",
    "        return super().action_to_move(action, battle)\n",
    "\n",
    "    def predict(self, obs):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).to(self.model.device)\n",
    "        obs_tensor = obs_tensor.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model.q_net(obs_tensor)\n",
    "            return int(torch.argmax(q_values).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Modèle chargé depuis Players/player_4\n",
      "📥 Modèle chargé depuis Players/player5_nn3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan2/Desktop/Télécom-master-spé/Projets_perso/Deep/Showdown_AI/my_showdown_ai_git/showdown_4/lib/python3.11/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "2025-06-17 14:08:17,104 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Whiscash', '[from] lockedmove'] in battle battle-gen4randombattle-200748 turn 7\n",
      "2025-06-17 14:08:17,116 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Entei', '[from] lockedmove'] in battle battle-gen4randombattle-200748 turn 8\n",
      "2025-06-17 14:08:17,139 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Blastoise', '[from] lockedmove'] in battle battle-gen4randombattle-200748 turn 11\n",
      "2025-06-17 14:08:17,145 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Mew', '[from] lockedmove'] in battle battle-gen4randombattle-200748 turn 12\n",
      "2025-06-17 14:08:18,526 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Flygon', 'Outrage', 'p2a: Sandslash', '[from] lockedmove'] in battle battle-gen4randombattle-200752 turn 49\n",
      "2025-06-17 14:08:18,537 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Flygon', 'Outrage', 'p2a: Sandslash', '[from] lockedmove'] in battle battle-gen4randombattle-200752 turn 50\n",
      "2025-06-17 14:08:18,642 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Azumarill', '[from] lockedmove'] in battle battle-gen4randombattle-200753 turn 4\n",
      "2025-06-17 14:08:18,651 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Azumarill', '[from] lockedmove'] in battle battle-gen4randombattle-200753 turn 6\n",
      "2025-06-17 14:08:18,659 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Venusaur', '[from] lockedmove'] in battle battle-gen4randombattle-200753 turn 7\n",
      "2025-06-17 14:08:18,670 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Mamoswine', '[from] lockedmove'] in battle battle-gen4randombattle-200753 turn 9\n",
      "2025-06-17 14:08:18,704 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Dragonite', 'Outrage', 'p1a: Magnezone', '[from] lockedmove'] in battle battle-gen4randombattle-200753 turn 13\n",
      "2025-06-17 14:08:18,895 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p1a: Vileplume', 'Solar Beam', 'p2a: Castform', '[from] lockedmove'] in battle battle-gen4randombattle-200754 turn 2\n",
      "2025-06-17 14:08:20,322 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Porygon2', '[from] lockedmove'] in battle battle-gen4randombattle-200758 turn 26\n",
      "2025-06-17 14:08:20,344 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Porygon2', '[from] lockedmove'] in battle battle-gen4randombattle-200758 turn 28\n",
      "2025-06-17 14:08:20,370 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Porygon2', '[from] lockedmove'] in battle battle-gen4randombattle-200758 turn 31\n",
      "2025-06-17 14:08:20,377 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Porygon2', '[from] lockedmove'] in battle battle-gen4randombattle-200758 turn 32\n",
      "2025-06-17 14:08:20,449 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Suicune', '[from] lockedmove'] in battle battle-gen4randombattle-200759 turn 6\n",
      "2025-06-17 14:08:20,472 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Salamence', 'Outrage', 'p1a: Suicune', '[from] lockedmove'] in battle battle-gen4randombattle-200759 turn 8\n",
      "2025-06-17 14:08:21,108 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Altaria', 'Outrage', 'p1a: Carnivine', '[from] lockedmove'] in battle battle-gen4randombattle-200760 turn 31\n",
      "2025-06-17 14:08:21,117 - AdversarialTrain 2 - WARNING - Unmanaged move message format received - cleaned up message ['', 'move', 'p2a: Altaria', 'Outrage', 'p1a: Hitmonchan', '[from] lockedmove'] in battle battle-gen4randombattle-200760 turn 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 3 victoires sur 40 matchs\n",
      "🎯 Reward moyen : -33.50\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "opponent = AdversarialTrainPlayer(battle_format=\"gen4randombattle\", log_level=30)\n",
    "eval_agent = Player5Test(battle_format=\"gen4randombattle\", opponent= opponent, log_level=30)\n",
    "\n",
    "n_eval_episodes = 40\n",
    "wins = 0\n",
    "rewards = []\n",
    "\n",
    "obs, _ = eval_agent.reset()\n",
    "for _ in range(n_eval_episodes):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = eval_agent.predict(obs)\n",
    "        obs, reward, terminated, truncated, _ = eval_agent.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        if done and reward > 0:\n",
    "            wins += 1\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    obs, _ = eval_agent.reset()\n",
    "\n",
    "print(f\"✅ {wins} victoires sur {n_eval_episodes} matchs\")\n",
    "print(f\"🎯 Reward moyen : {sum(rewards) / len(rewards):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100k : 28 victoires sur 40, reward = 16.51\n",
    "Entrainement adversarial player4, et eval contre player4 aussi : 4/40 (:/) (100k), 7/40 (200k), 9/40 (300k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "showdown_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33e7e3701f48ebda16bcd6f46fe6335779fe7b4b5fe34aacb01951541666ec3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
